{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e67f3d40",
   "metadata": {
    "cell_marker": "\"\"\""
   },
   "source": [
    "# Autoencoders\n",
    "\n",
    "An autoencoder is a type of artificial neural network used for learning\n",
    "efficient encodings of input data. It's essentially a network that attempts to\n",
    "replicate its input (encoding) as its output (decoding), but the network is\n",
    "designed in such a way that it must learn an efficient representation\n",
    "(compression) for the input data in order to map it back to itself.\n",
    "\n",
    "The importance of autoencoders lies in their ability to learn the underlying\n",
    "structure of complex data, making them valuable tools for scientific data\n",
    "analysis. Here's how:\n",
    "\n",
    "1. Dimensionality Reduction: Autoencoders can be used to reduce the\n",
    "dimensionality of high-dimensional data while preserving its essential\n",
    "characteristics. This is particularly useful in cases where the high\n",
    "dimensionality makes computations slow or the data overfitting occurs.\n",
    "\n",
    "2. Denoising: By training autoencoders on noisy versions of the data, they can\n",
    "learn to remove noise from the original data, making it cleaner and easier to\n",
    "analyze.\n",
    "\n",
    "3. Anomaly Detection: The encoder part of the autoencoder can be used to\n",
    "represent the input data in a lower-dimensional space. Any data point that is\n",
    "far from the rest in this space can be considered an anomaly, as it doesn't fit\n",
    "the pattern learned by the autoencoder during training.\n",
    "\n",
    "4. Generative Modeling: Autoencoders can be used as generative models, allowing\n",
    "them to generate new data that are similar to the original data. This can be\n",
    "useful in various scientific applications, such as creating synthetic data or\n",
    "for exploring the data space.\n",
    "\n",
    "5. Feature Learning: Autoencoders can learn useful features from raw data,\n",
    "which can then be used as inputs for other machine learning models, improving\n",
    "their performance.\n",
    "\n",
    "In summary, autoencoders are a powerful tool for scientific data analysis due\n",
    "to their ability to learn the underlying structure of complex data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5a919f6",
   "metadata": {
    "cell_marker": "\"\"\""
   },
   "source": [
    "## An autoencoder for denoising\n",
    "\n",
    "In the next cells, we will face a situation in which the quality of the data is\n",
    "rather poor. There is a lot of noise added to the dataset which is hard to\n",
    "handle. We will set up an autoencoder to tackle the task of **denoising**, i.e.\n",
    "to remove stochastic fluctuations from the input as best as possible.\n",
    "\n",
    "First, let's prepare a dataset, which is contains a signal we are interested in\n",
    "and the noise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69968e33",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Sequence\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from matplotlib import gridspec, pyplot as plt\n",
    "\n",
    "from mnist1d.data import get_dataset_args, make_dataset\n",
    "\n",
    "from utils import model_summary, MNIST1D\n",
    "\n",
    "np.random.seed(13)\n",
    "torch.random.manual_seed(12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad827ada",
   "metadata": {},
   "outputs": [],
   "source": [
    "# disable noise for a clear reference\n",
    "clean_config = get_dataset_args()\n",
    "clean_config.iid_noise_scale = 0\n",
    "clean_config.corr_noise_scale = 0\n",
    "clean_config.seed = 40\n",
    "clean = make_dataset(clean_config)\n",
    "cleanX, cleany = clean[\"x\"], clean[\"y\"]\n",
    "\n",
    "# use iid noise only for the time being\n",
    "noisy_config = get_dataset_args()\n",
    "noisy_config.iid_noise_scale = 0.05\n",
    "noisy_config.corr_noise_scale = 0\n",
    "noisy_config.seed = 40\n",
    "data = make_dataset(noisy_config)\n",
    "\n",
    "X, y = data[\"x\"], data[\"y\"]\n",
    "\n",
    "# 4000 data points of dimension 40\n",
    "print(f\"{X.shape=}\")\n",
    "print(f\"{y.shape=}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5489adc2",
   "metadata": {
    "cell_marker": "\"\"\""
   },
   "source": [
    "Now, let's plot the data which we would like to use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd868c74",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(2, 5, figsize=(14, 5), sharex=True, sharey=True)\n",
    "color_noisy = \"tab:blue\"\n",
    "color_clean = \"tab:orange\"\n",
    "\n",
    "for sample in range(10):\n",
    "    col = sample % 5\n",
    "    row = sample // 5\n",
    "    ax[row, col].plot(X[sample, ...], label=\"noisy\", color=color_noisy)\n",
    "    ax[row, col].plot(cleanX[sample, ...], label=\"clean\", color=color_clean)\n",
    "    label = y[sample]\n",
    "    ax[row, col].set_title(f\"label {label}\")\n",
    "    if row == 1:\n",
    "        ax[row, col].set_xlabel(f\"samples / a.u.\")\n",
    "    if col == 0:\n",
    "        ax[row, col].set_ylabel(f\"intensity / a.u.\")\n",
    "    if col == 4 and row == 0:\n",
    "        ax[row, col].legend()\n",
    "\n",
    "fig.suptitle(\"MNIST1D examples\")\n",
    "fig.savefig(\"mnist1d_noisy_first10.svg\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d250b338",
   "metadata": {
    "cell_marker": "\"\"\""
   },
   "source": [
    "As we can see, the data is filled with jitter. Furthermore, it is interesting\n",
    "to note that our dataset is still far from trivial. Have a look at all signals\n",
    "which are assigned to a certain label. Could you detect them?\n",
    "\n",
    "## Designing an autoencoder\n",
    "\n",
    "The [autoencoder architecture](https://en.wikipedia.org/wiki/Autoencoder) is\n",
    "well illustrated on Wikipedia. We reproduce [the\n",
    "image](https://commons.wikimedia.org/wiki/File:Autoencoder_schema.png) by\n",
    "[Michaela\n",
    "Massi](https://commons.wikimedia.org/w/index.php?title=User:Michela_Massi&action=edit&redlink=1)\n",
    "here for convenience: <div style=\"display: block;margin-left:\n",
    "auto;margin-right: auto;width: 75%;\"><img\n",
    "src=\"https://upload.wikimedia.org/wikipedia/commons/3/37/Autoencoder_schema.png\"\n",
    "alt=\"autoencoder schematic from Wikipedia by Michaela Massi, CC-BY 4.0\"></div>\n",
    "\n",
    "The architecture consists of three parts:\n",
    "\n",
    "1. **the encoder** on the left: this small network ingests the input data `X`\n",
    "   and compresses it into a smaller shape\n",
    "2. the **code** in the center: this is the \"bottleneck\" which holds the\n",
    "   **latent representation** of your input data\n",
    "3. **the decoder** on the right: reconstructs the output from the latent code\n",
    "\n",
    "The task of the autoencoder is to reconstruct the input as best as possible.\n",
    "This task is far from easy, as the autoencoder is forced to shrink the data\n",
    "into the latent space."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd6ae337",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyEncoder(torch.nn.Module):\n",
    "    def __init__(self, nlayers=3, nchannels=16):\n",
    "        super().__init__()\n",
    "        self.layers = torch.nn.Sequential()\n",
    "\n",
    "        self.layers.append(\n",
    "            torch.nn.Conv1d(\n",
    "                in_channels=1,\n",
    "                out_channels=nchannels,\n",
    "                kernel_size=3,\n",
    "                padding=1,\n",
    "                stride=1,\n",
    "            )\n",
    "        )\n",
    "\n",
    "        for i in range(nlayers - 1):\n",
    "            # convolve and shrink input width by 2x\n",
    "            self.layers.append(\n",
    "                torch.nn.Conv1d(\n",
    "                    in_channels=nchannels,\n",
    "                    out_channels=nchannels,\n",
    "                    kernel_size=3,\n",
    "                    padding=1,\n",
    "                    stride=1,\n",
    "                )\n",
    "            )\n",
    "            self.layers.append(torch.nn.ReLU())\n",
    "            self.layers.append(\n",
    "                torch.nn.Conv1d(\n",
    "                    in_channels=nchannels,\n",
    "                    out_channels=nchannels,\n",
    "                    kernel_size=3,\n",
    "                    padding=1,\n",
    "                    stride=2,\n",
    "                )\n",
    "            )\n",
    "\n",
    "        # convolve and keep input width\n",
    "        self.layers.append(\n",
    "            torch.nn.Conv1d(\n",
    "                in_channels=nchannels, out_channels=1, kernel_size=3, padding=1\n",
    "            )\n",
    "        )\n",
    "\n",
    "        # flatten and add a linear tail\n",
    "        self.layers.append(torch.nn.Flatten())\n",
    "\n",
    "    def forward(self, x):\n",
    "        # convolutions in torch require an explicit channel dimension to be\n",
    "        # present in the data in other words:\n",
    "        # inputs of size (nbatch, 40) do not work,\n",
    "        # inputs of size (nbatch, 1, 40) do work\n",
    "        if len(x.shape) == 2:\n",
    "            return self.layers(torch.unsqueeze(x, dim=1))\n",
    "        else:\n",
    "            return self.layers(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02839f49",
   "metadata": {},
   "outputs": [],
   "source": [
    "enc = MyEncoder()\n",
    "\n",
    "# convert input data to torch.Tensor and convert to torch.float32\n",
    "Xt = torch.from_numpy(X).float()\n",
    "\n",
    "# extract only first 8 samples for testing\n",
    "Xtest = Xt[:8, ...]\n",
    "\n",
    "latent_h = enc(Xtest)\n",
    "\n",
    "assert (\n",
    "    latent_h.shape[-1] < Xtest.shape[-1]\n",
    "), f\"{latent_h.shape[-1]} !< {Xtest.shape[-1]}\"\n",
    "\n",
    "print(f\"{Xt[:1, ...].shape=}\")\n",
    "model_summary(enc, input_size=Xt[:1, ...].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bccdbab",
   "metadata": {
    "cell_marker": "\"\"\""
   },
   "source": [
    "The encoder has been constructed. Now, we need to add a decoder object to\n",
    "reconstruct from the latent space."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c900a462",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyDecoder(torch.nn.Module):\n",
    "    def __init__(self, nlayers=3, nchannels=16):\n",
    "        super().__init__()\n",
    "        self.layers = torch.nn.Sequential()\n",
    "\n",
    "        for i in range(nlayers - 1):\n",
    "            inchannels = 1 if i == 0 else nchannels\n",
    "            # deconvolve/upsample and grow input width by 2x\n",
    "            self.layers.append(\n",
    "                torch.nn.ConvTranspose1d(\n",
    "                    in_channels=inchannels,\n",
    "                    out_channels=nchannels,\n",
    "                    kernel_size=5,\n",
    "                    padding=2,\n",
    "                    stride=2,\n",
    "                    output_padding=1,\n",
    "                )\n",
    "            )\n",
    "            self.layers.append(torch.nn.ReLU())\n",
    "            self.layers.append(\n",
    "                torch.nn.Conv1d(\n",
    "                    in_channels=nchannels,\n",
    "                    out_channels=nchannels,\n",
    "                    kernel_size=3,\n",
    "                    padding=1,\n",
    "                    stride=1,\n",
    "                )\n",
    "            )\n",
    "\n",
    "        # convolve and keep input width\n",
    "        self.layers.append(\n",
    "            torch.nn.Conv1d(\n",
    "                in_channels=nchannels, out_channels=1, kernel_size=3, padding=1\n",
    "            )\n",
    "        )\n",
    "\n",
    "        self.layers.append(torch.nn.Flatten())\n",
    "\n",
    "    def forward(self, x):\n",
    "        # convolutions in torch require an explicit channel dimension to be\n",
    "        # present in the data in other words:\n",
    "        # inputs of size (nbatch, 40) do not work,\n",
    "        # inputs of size (nbatch, 1, 40) do work\n",
    "        if len(x.shape) == 2:\n",
    "            return self.layers(torch.unsqueeze(x, dim=1))\n",
    "        else:\n",
    "            return self.layers(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73bf6999",
   "metadata": {},
   "outputs": [],
   "source": [
    "dec = MyDecoder()\n",
    "\n",
    "Xt_prime = dec(latent_h)\n",
    "assert (\n",
    "    Xt_prime.squeeze(1).shape == Xtest.shape\n",
    "), f\"{Xt_prime.squeeze(1).shape} != {Xtest.shape}\"\n",
    "\n",
    "print(f\"{latent_h[:1, ...].shape=}\")\n",
    "model_summary(dec, input_size=latent_h[:1, ...].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af4be846",
   "metadata": {
    "cell_marker": "\"\"\""
   },
   "source": [
    "We have now all the lego bricks in place to compose an autoencoder. We do this\n",
    "by combining the encoder and decoder in yet another `torch.nn.Module`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66f3c500",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyAutoencoder(torch.nn.Module):\n",
    "    def __init__(self, nlayers=3, nchannels=16):\n",
    "        super().__init__()\n",
    "\n",
    "        self.enc = MyEncoder(nlayers, nchannels)\n",
    "        self.dec = MyDecoder(nlayers, nchannels)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # construct the latents\n",
    "        h = self.enc(x)\n",
    "\n",
    "        # perform reconstruction\n",
    "        x_prime = self.dec(h)\n",
    "\n",
    "        return x_prime"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88dc591f",
   "metadata": {
    "cell_marker": "\"\"\""
   },
   "source": [
    "We can test our autoencoder to make sure it works as expected similar to what we did above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32202a45",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "model = MyAutoencoder()\n",
    "Xt_prime = model(Xtest)\n",
    "\n",
    "assert (\n",
    "    Xt_prime.squeeze(1).shape == Xtest.shape\n",
    "), f\"{Xt_prime.squeeze(1).shape} != {Xtest.shape}\"\n",
    "\n",
    "print(f\"{Xt[:1, ...].shape=}\")\n",
    "model_summary(model, input_size=Xt[:1, ...].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "562e8a0e",
   "metadata": {
    "cell_marker": "\"\"\""
   },
   "source": [
    "## Training an autoencoder\n",
    "\n",
    "Training the autoencoder works in the same line as training for regression from the last episode.\n",
    "\n",
    "1. create the dataset\n",
    "2. create the loaders\n",
    "3. setup the model\n",
    "4. setup the optimizer\n",
    "5. loop through epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b24b197",
   "metadata": {},
   "outputs": [],
   "source": [
    "# noisy data\n",
    "dataset_train_noisy = MNIST1D(mnist1d_args=noisy_config, train=True)\n",
    "dataset_test_noisy = MNIST1D(mnist1d_args=noisy_config, train=False)\n",
    "\n",
    "# clean data\n",
    "dataset_train_clean = MNIST1D(mnist1d_args=clean_config, train=True)\n",
    "dataset_test_clean = MNIST1D(mnist1d_args=clean_config, train=False)\n",
    "\n",
    "# stacked as paired sequences, like Python's zip()\n",
    "dataset_train = torch.utils.data.StackDataset(\n",
    "    dataset_train_noisy, dataset_train_clean\n",
    ")\n",
    "dataset_test = torch.utils.data.StackDataset(\n",
    "    dataset_test_noisy, dataset_test_clean\n",
    ")\n",
    "\n",
    "batch_size = 64\n",
    "train_dataloader = DataLoader(\n",
    "    dataset_train, batch_size=batch_size, shuffle=True\n",
    ")\n",
    "test_dataloader = DataLoader(\n",
    "    dataset_test, batch_size=batch_size, shuffle=False\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86c1d285",
   "metadata": {},
   "source": [
    "\n",
    "Let's inspect the data produced by the DataLoader. We look at the first batch\n",
    "of data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e26f3ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_noisy, train_clean = next(iter(train_dataloader))\n",
    "print(f\"{len(train_noisy)=} {len(train_clean)=}\")\n",
    "X_train_noisy, y_train_noisy = train_noisy\n",
    "X_train_clean, y_train_clean = train_clean\n",
    "print(f\"{X_train_noisy.shape=} {y_train_noisy.shape=}\")\n",
    "print(f\"{X_train_clean.shape=} {y_train_clean.shape=}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94621645",
   "metadata": {
    "cell_marker": "\"\"\""
   },
   "source": [
    "We observe:\n",
    "\n",
    "* The DataLoader (via the MNIST1D custom Dataset) has added a channel\n",
    "  dimension, such that in each batch of `batch_size=64`, `X.shape` is [64, 1,\n",
    "  40] rather than [64, 40]. That is just a convenience feature. Our model can\n",
    "  handle either.\n",
    "* The DataLoader also returns the labels `y_train_*` since that is part of the\n",
    "  MNIST1D Dataset. We will discard them below, since for training an\n",
    "  autoencoder, we only need the inputs X."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "647d94f2",
   "metadata": {
    "cell_marker": "\"\"\""
   },
   "source": [
    "Now lets iterate through the data and verify that we combined the correct noisy\n",
    "and clean data points using StackDataset. We will look at the first `nrows *\n",
    "ncols` batches. For each batch, we plot noisy and clean data for a randomly\n",
    "picked data point `idx_in_batch`, which can be any number between 0 and\n",
    "`batch_size`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b5a02ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "grid = gridspec.GridSpec(nrows=3, ncols=4)\n",
    "fig = plt.figure(figsize=(5 * grid.ncols, 5 * grid.nrows))\n",
    "\n",
    "for batch_idx, (gs, (train_noisy, train_clean)) in enumerate(\n",
    "    zip(grid, train_dataloader)\n",
    "):\n",
    "    X_train_noisy, y_train_noisy = train_noisy\n",
    "    X_train_clean, y_train_clean = train_clean\n",
    "    assert (y_train_noisy == y_train_clean).all()\n",
    "    ax = fig.add_subplot(gs)\n",
    "    idx_in_batch = np.random.randint(0, len(y_train_noisy))\n",
    "    ax.plot(\n",
    "        X_train_noisy[idx_in_batch].squeeze(), label=\"noisy\", color=color_noisy\n",
    "    )\n",
    "    ax.plot(\n",
    "        X_train_clean[idx_in_batch].squeeze(), label=\"clean\", color=color_clean\n",
    "    )\n",
    "    title = \"\\n\".join(\n",
    "        (\n",
    "            f\"batch={batch_idx+1} {idx_in_batch=}\",\n",
    "            f\"labels: noisy={y_train_noisy[idx_in_batch]} clean={y_train_clean[idx_in_batch]}\",\n",
    "        )\n",
    "    )\n",
    "    ax.set_title(title)\n",
    "    ax.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "575aa493",
   "metadata": {},
   "outputs": [],
   "source": [
    "nsamples = len(dataset_train_noisy) + len(dataset_test_noisy)\n",
    "assert (\n",
    "    nsamples == 4_000\n",
    "), f\"number of samples for MNIST1D is not 4_000 but {nsamples}\"\n",
    "\n",
    "model = MyAutoencoder(nchannels=32)\n",
    "print(f\"{Xt[:1, ...].shape=}\")\n",
    "print(\n",
    "    model_summary(model, input_size=next(iter(train_dataloader))[0][0].shape)\n",
    ")\n",
    "\n",
    "learning_rate = 1e-3\n",
    "max_epochs = 20\n",
    "log_every = 5\n",
    "\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=learning_rate)\n",
    "criterion = torch.nn.MSELoss()  # our loss function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f6d2655",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_autoencoder(\n",
    "    model,\n",
    "    opt,\n",
    "    crit,\n",
    "    train_dataloader,\n",
    "    test_dataloader,\n",
    "    max_epochs,\n",
    "    log_every=5,\n",
    "    use_gpu=False,\n",
    "):\n",
    "    results = {\"train_losses\": [], \"test_losses\": []}\n",
    "    ntrainsteps = len(train_dataloader)\n",
    "    nteststeps = len(test_dataloader)\n",
    "    train_loss, test_loss = (\n",
    "        torch.empty((ntrainsteps,)),\n",
    "        torch.empty((nteststeps,)),\n",
    "    )\n",
    "\n",
    "    if use_gpu and torch.cuda.is_available():\n",
    "        device = torch.device(\"cuda:0\")\n",
    "    else:\n",
    "        device = torch.device(\"cpu\")\n",
    "\n",
    "    model = model.to(device)\n",
    "    model.train()\n",
    "\n",
    "    for epoch in range(max_epochs):\n",
    "        # perform train for one epoch\n",
    "        for idx, (train_noisy, train_clean) in enumerate(train_dataloader):\n",
    "            # Discard labels if using StackDataset\n",
    "            if isinstance(train_noisy, Sequence):\n",
    "                X_train_noisy = train_noisy[0]\n",
    "                X_train_clean = train_clean[0]\n",
    "            else:\n",
    "                X_train_noisy = train_noisy\n",
    "                X_train_clean = train_clean\n",
    "\n",
    "            # forward pass\n",
    "            X_prime_train = model(X_train_noisy.to(device))\n",
    "\n",
    "            # compute loss\n",
    "            loss = crit(X_prime_train, X_train_clean.squeeze().to(device))\n",
    "\n",
    "            # compute gradient\n",
    "            loss.backward()\n",
    "\n",
    "            # apply weight update rule\n",
    "            opt.step()\n",
    "\n",
    "            # set gradients to 0\n",
    "            opt.zero_grad()\n",
    "\n",
    "            train_loss[idx] = loss.item()\n",
    "\n",
    "        for idx, (test_noisy, test_clean) in enumerate(test_dataloader):\n",
    "            # Discard labels if using StackDataset\n",
    "            if isinstance(test_noisy, Sequence):\n",
    "                X_test_noisy = test_noisy[0]\n",
    "                X_test_clean = test_clean[0]\n",
    "            else:\n",
    "                X_test_noisy = test_noisy\n",
    "                X_test_clean = test_clean\n",
    "\n",
    "            X_prime_test = model(X_test_noisy.to(device))\n",
    "            loss_ = crit(X_prime_test, X_test_clean.squeeze().to(device))\n",
    "            test_loss[idx] = loss_.item()\n",
    "\n",
    "        results[\"train_losses\"].append(train_loss.mean())\n",
    "        results[\"test_losses\"].append(test_loss.mean())\n",
    "\n",
    "        if (epoch + 1) % log_every == 0 or (epoch + 1) == max_epochs:\n",
    "            print(\n",
    "                f\"{epoch+1:02.0f}/{max_epochs} :: training loss {train_loss.mean():03.4f}; test loss {test_loss.mean():03.4f}\"\n",
    "            )\n",
    "    return results\n",
    "\n",
    "\n",
    "results = train_autoencoder(\n",
    "    model,\n",
    "    optimizer,\n",
    "    criterion,\n",
    "    train_dataloader,\n",
    "    test_dataloader,\n",
    "    max_epochs,\n",
    "    log_every,\n",
    ")\n",
    "\n",
    "model = model.cpu()\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e374f483",
   "metadata": {
    "cell_marker": "\"\"\""
   },
   "source": [
    "# Plot loss (train progress) and predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2dec004",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "ax.plot(results[\"train_losses\"], color=\"b\", label=\"train\")\n",
    "ax.plot(results[\"test_losses\"], color=\"orange\", label=\"test\")\n",
    "ax.set_xlabel(\"epoch\")\n",
    "ax.set_ylabel(\"average MSE Loss / a.u.\")\n",
    "ax.set_yscale(\"log\")\n",
    "ax.set_title(\"Loss\")\n",
    "ax.legend()\n",
    "fig.savefig(\"mnist1d_noisy_conv_autoencoder_loss.svg\")\n",
    "\n",
    "\n",
    "with torch.no_grad():\n",
    "    grid = gridspec.GridSpec(nrows=3, ncols=4)\n",
    "    fig = plt.figure(figsize=(5 * grid.ncols, 5 * grid.nrows))\n",
    "\n",
    "    for batch_idx, (gs, (test_noisy, test_clean)) in enumerate(\n",
    "        zip(grid, test_dataloader)\n",
    "    ):\n",
    "        X_test_noisy, y_test_noisy = test_noisy\n",
    "        X_test_clean, y_test_clean = test_clean\n",
    "        assert (y_test_noisy == y_test_clean).all()\n",
    "        ax = fig.add_subplot(gs)\n",
    "        idx_in_batch = np.random.randint(0, len(y_test_noisy))\n",
    "        ax.plot(\n",
    "            X_test_noisy[idx_in_batch].squeeze(),\n",
    "            label=\"noisy\",\n",
    "            color=color_noisy,\n",
    "        )\n",
    "        ax.plot(\n",
    "            X_test_clean[idx_in_batch].squeeze(),\n",
    "            label=\"clean\",\n",
    "            color=color_clean,\n",
    "        )\n",
    "        ax.plot(\n",
    "            model(X_test_noisy[idx_in_batch]).squeeze(),\n",
    "            label=\"prediction\",\n",
    "            color=\"tab:red\",\n",
    "            lw=2,\n",
    "        )\n",
    "        title = \"\\n\".join(\n",
    "            (\n",
    "                f\"batch={batch_idx+1} {idx_in_batch=}\",\n",
    "                f\"labels: noisy={y_test_noisy[idx_in_batch]} clean={y_test_clean[idx_in_batch]}\",\n",
    "            )\n",
    "        )\n",
    "        ax.set_title(title)\n",
    "        ax.legend()\n",
    "\n",
    "fig.savefig(\"mnist1d_noisy_conv_autoencoder_predictions.svg\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d234c6a2",
   "metadata": {
    "cell_marker": "\"\"\""
   },
   "source": [
    "We can see that the autoencoder smoothed the input signal when producing a\n",
    "reconstruction. This denoising effect can be quite helpful in practice. The\n",
    "core reasons for this effect are:\n",
    "\n",
    "1. The bottleneck (producing the latent representation) in the architecture\n",
    "   forces the model to generalize the input data.\n",
    "2. We train using the mean squared error as the loss function,\n",
    "   this has a smoothing effect as well as the learning goal for the model is\n",
    "   effectively to produce low differences on average.\n",
    "3. We use convolutions which slide across the data and hence can incur a\n",
    "   smoothing effect."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f433ffd6",
   "metadata": {
    "cell_marker": "\"\"\""
   },
   "source": [
    "## **Exercise 04.1** Vary autoencoder hyper-parameters\n",
    "\n",
    "The model predictions are actually not very good -- too much smoothing in some\n",
    "parts of a signal, following the input signal too much in other parts. The same\n",
    "could probably be acheived by a much simpler method such as a moving average :)\n",
    "\n",
    "Try to improve this by varying the following parameters and observe their\n",
    "effect on the reconstruction. Re-execute the cells above which define the model,\n",
    "set the hyper-parameters and run the training.\n",
    "\n",
    "Model architecture:\n",
    "\n",
    "* nchannels\n",
    "* nlayers (bigger means smaller latent space size)\n",
    "\n",
    "Training:\n",
    "\n",
    "* learning_rate\n",
    "* max_epochs"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "formats": "ipynb,py:percent"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
