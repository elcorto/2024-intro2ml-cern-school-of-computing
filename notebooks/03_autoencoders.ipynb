{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "485597c1",
   "metadata": {
    "cell_marker": "\"\"\""
   },
   "source": [
    "# Autoencoders\n",
    "\n",
    "An autoencoder is a type of artificial neural network used for learning\n",
    "efficient encodings of input data. It's essentially a network that attempts to\n",
    "replicate its input (encoding) as its output (decoding), but the network is\n",
    "designed in such a way that it must learn an efficient representation\n",
    "(compression) for the input data in order to map it back to itself.\n",
    "\n",
    "The importance of autoencoders lies in their ability to learn the underlying\n",
    "structure of complex data, making them valuable tools for scientific data\n",
    "analysis. Here's how:\n",
    "\n",
    "1. Dimensionality Reduction: Autoencoders can be used to reduce the\n",
    "dimensionality of high-dimensional data while preserving its essential\n",
    "characteristics. This is particularly useful in cases where the high\n",
    "dimensionality makes computations slow or the data overfitting occurs.\n",
    "\n",
    "2. Denoising: By training autoencoders on noisy versions of the data, they can\n",
    "learn to remove noise from the original data, making it cleaner and easier to\n",
    "analyze.\n",
    "\n",
    "3. Anomaly Detection: The encoder part of the autoencoder can be used to\n",
    "represent the input data in a lower-dimensional space. Any data point that is\n",
    "far from the rest in this space can be considered an anomaly, as it doesn't fit\n",
    "the pattern learned by the autoencoder during training.\n",
    "\n",
    "4. Generative Modeling: Autoencoders can be used as generative models, allowing\n",
    "them to generate new data that are similar to the original data. This can be\n",
    "useful in various scientific applications, such as creating synthetic data or\n",
    "for exploring the data space.\n",
    "\n",
    "5. Feature Learning: Autoencoders can learn useful features from raw data,\n",
    "which can then be used as inputs for other machine learning models, improving\n",
    "their performance.\n",
    "\n",
    "In summary, autoencoders are a powerful tool for scientific data analysis due\n",
    "to their ability to learn the underlying structure of complex data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa4c59ce",
   "metadata": {
    "cell_marker": "\"\"\""
   },
   "source": [
    "## An autoencoder for denoising\n",
    "\n",
    "In the next cells, we will face a situation in which the quality of the data is\n",
    "rather poor. There is a lot of noise added to the dataset which is hard to\n",
    "handle. We will set up an autoencoder to tackle the task of **denoising**, i.e.\n",
    "to remove stochastic fluctuations from the input as best as possible.\n",
    "\n",
    "First, let's prepare a dataset which contains a noisy signal that we wish to\n",
    "denoise. For that we use the MNIST-1D dataset from earlier and add artificial\n",
    "noise. The autoencoder's task is to remove this noise by learning the\n",
    "characteristics of the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "914fcf83",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Sequence\n",
    "from collections import defaultdict\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from matplotlib import gridspec, pyplot as plt\n",
    "\n",
    "from mnist1d.data import get_dataset_args, make_dataset\n",
    "\n",
    "from utils import model_summary, MNIST1D, colors_10\n",
    "\n",
    "\n",
    "np.random.seed(13)\n",
    "torch.random.manual_seed(12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "904ef375",
   "metadata": {},
   "outputs": [],
   "source": [
    "# disable noise for a clear reference\n",
    "clean_config = get_dataset_args()\n",
    "clean_config.iid_noise_scale = 0\n",
    "clean_config.corr_noise_scale = 0\n",
    "clean_config.seed = 40\n",
    "clean_mnist1d = make_dataset(clean_config)\n",
    "X_clean, y_clean = clean_mnist1d[\"x\"], clean_mnist1d[\"y\"]\n",
    "\n",
    "# use iid noise only for the time being\n",
    "noisy_config = get_dataset_args()\n",
    "noisy_config.iid_noise_scale = 0.05\n",
    "noisy_config.corr_noise_scale = 0\n",
    "noisy_config.seed = 40\n",
    "noisy_mnist1d = make_dataset(noisy_config)\n",
    "X_noisy, y_noisy = noisy_mnist1d[\"x\"], noisy_mnist1d[\"y\"]\n",
    "\n",
    "# We use the same random seed for clean_config and noisy_config, so this must\n",
    "# be the same.\n",
    "assert (y_clean == y_noisy).all()\n",
    "\n",
    "# Convert numpy -> torch for usage in next cells. For training, we will build a\n",
    "# DataLoader later.\n",
    "X_noisy = torch.from_numpy(X_noisy).float()\n",
    "\n",
    "# 4000 data points of dimension 40\n",
    "print(f\"{X_noisy.shape=}\")\n",
    "print(f\"{y_noisy.shape=}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8f1d93b",
   "metadata": {
    "cell_marker": "\"\"\""
   },
   "source": [
    "Now, let's plot the data which we would like to use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3a8ab04",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(2, 5, figsize=(14, 5), sharex=True, sharey=True)\n",
    "color_noisy = \"tab:blue\"\n",
    "color_clean = \"tab:orange\"\n",
    "\n",
    "for sample in range(10):\n",
    "    col = sample % 5\n",
    "    row = sample // 5\n",
    "    ax[row, col].plot(X_noisy[sample, ...], label=\"noisy\", color=color_noisy)\n",
    "    ax[row, col].plot(X_clean[sample, ...], label=\"clean\", color=color_clean)\n",
    "    label = y_noisy[sample]\n",
    "    ax[row, col].set_title(f\"label {label}\")\n",
    "    if row == 1:\n",
    "        ax[row, col].set_xlabel(\"samples / a.u.\")\n",
    "    if col == 0:\n",
    "        ax[row, col].set_ylabel(\"intensity / a.u.\")\n",
    "    if col == 4 and row == 0:\n",
    "        ax[row, col].legend()\n",
    "\n",
    "fig.suptitle(\"MNIST-1D examples\")\n",
    "fig.savefig(\"mnist1d_noisy_first10.svg\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c1b82b0",
   "metadata": {
    "cell_marker": "\"\"\""
   },
   "source": [
    "As we can see, the data is filled with jitter. Furthermore, it is interesting\n",
    "to note that our dataset is still far from trivial. Have a look at all signals\n",
    "which are assigned to a certain label. Could you detect them?\n",
    "\n",
    "## Designing an autoencoder\n",
    "\n",
    "The [autoencoder architecture](https://en.wikipedia.org/wiki/Autoencoder) is\n",
    "well illustrated on Wikipedia. We reproduce [the\n",
    "image](https://commons.wikimedia.org/wiki/File:Autoencoder_schema.png) by\n",
    "[Michaela\n",
    "Massi](https://commons.wikimedia.org/w/index.php?title=User:Michela_Massi&action=edit&redlink=1)\n",
    "here for convenience: <div style=\"display: block;margin-left:\n",
    "auto;margin-right: auto;width: 75%;\"><img\n",
    "src=\"https://upload.wikimedia.org/wikipedia/commons/3/37/Autoencoder_schema.png\"\n",
    "alt=\"autoencoder schematic from Wikipedia by Michaela Massi, CC-BY 4.0\"></div>\n",
    "\n",
    "The architecture consists of three parts:\n",
    "\n",
    "1. **the encoder** on the left: this small network ingests the input data `X`\n",
    "   and compresses it into a smaller shape\n",
    "2. the **code** in the center: this is the \"bottleneck\" which holds the\n",
    "   **latent representation** `h`\n",
    "3. **the decoder** on the right: reconstructs the output `X'` from the latent code `h`\n",
    "\n",
    "The task of the autoencoder is to reconstruct the input as best as possible.\n",
    "This task is far from easy, as the autoencoder is forced to shrink the data\n",
    "into the latent space.\n",
    "\n",
    "In our **denoising** case, the task is even harder, since the autoencoder shall\n",
    "not only reconstruct clean data from clean inputs, but is given noisy inputs\n",
    "and is tasked to reconstruct the unknown clean version.\n",
    "\n",
    "Since we have the same MNIST-1D data as before, we'll use convolutional\n",
    "layers to build the autoencoder. In particular, we follow this design for 2D\n",
    "convolutions of images, adapted to our 1D case.\n",
    "\n",
    "![image](img/guo_2017_cae.png)\n",
    "\n",
    "Guo et al. \"Deep Clustering with Convolutional Autoencoders\", 2017 (https://doi.org/10.1007/978-3-319-70096-0_39)\n",
    "\n",
    "Other resources:\n",
    "\n",
    "* https://lightning.ai/docs/pytorch/stable/notebooks/course_UvA-DL/08-deep-autoencoders.html\n",
    "* https://github.com/fquaren/Deep-Clustering-with-Convolutional-Autoencoders/blob/master/src/nets.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05582ad8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyEncoder(torch.nn.Module):\n",
    "    def __init__(self, channels=[8, 16, 32], input_ndim=40, latent_ndim=10):\n",
    "        super().__init__()\n",
    "        self.layers = torch.nn.Sequential()\n",
    "\n",
    "        channels = [1] + channels\n",
    "        for ii, (old_n_channels, new_n_channels) in enumerate(\n",
    "            zip(channels[:-1], channels[1:])\n",
    "        ):\n",
    "            self.layers.append(\n",
    "                torch.nn.Conv1d(\n",
    "                    in_channels=old_n_channels,\n",
    "                    out_channels=new_n_channels,\n",
    "                    kernel_size=3,\n",
    "                    padding=1,\n",
    "                    padding_mode=\"replicate\",\n",
    "                    stride=2,\n",
    "                )\n",
    "            )\n",
    "            if ii < len(channels) - 2:\n",
    "                self.layers.append(\n",
    "                    torch.nn.Conv1d(\n",
    "                        in_channels=new_n_channels,\n",
    "                        out_channels=new_n_channels,\n",
    "                        kernel_size=3,\n",
    "                        padding=1,\n",
    "                        padding_mode=\"replicate\",\n",
    "                        stride=1,\n",
    "                    )\n",
    "                )\n",
    "            self.layers.append(torch.nn.ReLU())\n",
    "\n",
    "        self.layers.append(torch.nn.Flatten())\n",
    "\n",
    "        # Calculate in_features for Linear layer\n",
    "        dummy_X = torch.empty(1, 1, input_ndim, device=\"meta\")\n",
    "        dummy_out = self.layers(dummy_X)\n",
    "        in_features = dummy_out.shape[-1]\n",
    "\n",
    "        # Compress conv results into latent space\n",
    "        self.layers.append(\n",
    "            torch.nn.Linear(\n",
    "                in_features=in_features,\n",
    "                out_features=latent_ndim,\n",
    "            )\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Convolutions in torch require an explicit channel dimension to be\n",
    "        # present in the data, in other words:\n",
    "        #   inputs of size (batch_size, 40) do not work,\n",
    "        #   inputs of size (batch_size, 1, 40) do work\n",
    "        if len(x.shape) == 2:\n",
    "            return self.layers(torch.unsqueeze(x, dim=1))\n",
    "        else:\n",
    "            return self.layers(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24d1a8f8",
   "metadata": {
    "cell_marker": "\"\"\""
   },
   "source": [
    "This encoder is not yet trained, so its weights are random. Still, lets apply\n",
    "this to some input data and observe the input and output shapes. For this we'll\n",
    "use the `model_summary()` helper function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39952d72",
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    enc = MyEncoder()\n",
    "\n",
    "    # extract only first 8 samples for testing\n",
    "    X_test = X_noisy[:8, ...]\n",
    "\n",
    "    X_latent_h = enc(X_test)\n",
    "\n",
    "    assert (\n",
    "        X_latent_h.shape[-1] < X_test.shape[-1]\n",
    "    ), f\"{X_latent_h.shape[-1]} !< {X_test.shape[-1]}\"\n",
    "\n",
    "    print(f\"{X_test[:1, ...].shape=}\")\n",
    "    print(model_summary(enc, input_size=X_test[:1, ...].shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ada834f6",
   "metadata": {
    "cell_marker": "\"\"\""
   },
   "source": [
    "The encoder takes a tensor of shape `[batch_size, 40]` (or `[batch_size, 1,\n",
    "40]` with a channel dimension) and compresses that to a latent `h` of shape\n",
    "`[batch_size, latent_ndim]`. Above, we used `batch_size=1` when calling\n",
    "`model_summary()`.\n",
    "\n",
    "The encoder has been constructed. Now, we need to add a decoder object to\n",
    "reconstruct from the latent space."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f83bd2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyDecoder(torch.nn.Module):\n",
    "    def __init__(self, channels=[32, 16, 8], latent_ndim=10, output_ndim=40):\n",
    "        super().__init__()\n",
    "        self.layers = torch.nn.Sequential()\n",
    "\n",
    "        # Architecture of the full autoencoder. Used here to help explain the\n",
    "        # calculation of smallest_conv_ndim and linear_ndim.\n",
    "        #\n",
    "        # With channels=[32, 16, 8], latent_ndim=10, output_ndim=40, we have\n",
    "        #\n",
    "        #   smallest_conv_ndim = 5 = 40 // 2**3\n",
    "        #\n",
    "        # since we reduce input_ndim = output_ndim = 40 by factor of 2 in each\n",
    "        # of the len(channels) = 3 conv steps in the encoder because of\n",
    "        # Conv1d(..., stride=2).\n",
    "        #\n",
    "        # Further, we have\n",
    "        #\n",
    "        #   linear_ndim = 160 = 32 * 5\n",
    "        #\n",
    "        # ======================================================================\n",
    "        # Layer (type:depth-idx)                   Input Shape     Output Shape\n",
    "        # ======================================================================\n",
    "        # MyAutoencoder                            [1, 40]         [1, 40]\n",
    "        # ├─MyEncoder: 1-1                         [1, 40]         [1, 10]\n",
    "        # │    └─Sequential: 2-1                   [1, 1, 40]      [1, 10]\n",
    "        # │    │    └─Conv1d: 3-1                  [1, 1, 40]      [1, 8, 20]\n",
    "        # │    │    └─Conv1d: 3-2                  [1, 8, 20]      [1, 8, 20]\n",
    "        # │    │    └─ReLU: 3-3                    [1, 8, 20]      [1, 8, 20]\n",
    "        # │    │    └─Conv1d: 3-4                  [1, 8, 20]      [1, 16, 10]\n",
    "        # │    │    └─Conv1d: 3-5                  [1, 16, 10]     [1, 16, 10]\n",
    "        # │    │    └─ReLU: 3-6                    [1, 16, 10]     [1, 16, 10]\n",
    "        # │    │    └─Conv1d: 3-7                  [1, 16, 10]     [1, 32, 5]\n",
    "        # │    │    └─ReLU: 3-8                    [1, 32, 5]      [1, 32, 5]\n",
    "        # │    │    └─Flatten: 3-9                 [1, 32, 5]      [1, 160]\n",
    "        # │    │    └─Linear: 3-10                 [1, 160]        [1, 10]\n",
    "        # ├─MyDecoder: 1-2                         [1, 10]         [1, 40]\n",
    "        # │    └─Sequential: 2-2                   [1, 10]         [1, 40]\n",
    "        # │    │    └─Linear: 3-11                 [1, 10]         [1, 160]\n",
    "        # │    │    └─ReLU: 3-12                   [1, 160]        [1, 160]\n",
    "        # │    │    └─Unflatten: 3-13              [1, 160]        [1, 32, 5]\n",
    "        # │    │    └─ConvTranspose1d: 3-14        [1, 32, 5]      [1, 16, 10]\n",
    "        # │    │    └─Conv1d: 3-15                 [1, 16, 10]     [1, 16, 10]\n",
    "        # │    │    └─ReLU: 3-16                   [1, 16, 10]     [1, 16, 10]\n",
    "        # │    │    └─ConvTranspose1d: 3-17        [1, 16, 10]     [1, 8, 20]\n",
    "        # │    │    └─Conv1d: 3-18                 [1, 8, 20]      [1, 8, 20]\n",
    "        # │    │    └─ReLU: 3-19                   [1, 8, 20]      [1, 8, 20]\n",
    "        # │    │    └─ConvTranspose1d: 3-20        [1, 8, 20]      [1, 1, 40]\n",
    "        # │    │    └─Flatten: 3-21                [1, 1, 40]      [1, 40]\n",
    "        # ======================================================================\n",
    "\n",
    "        smallest_conv_ndim = output_ndim // (2 ** len(channels))\n",
    "        linear_ndim = channels[0] * smallest_conv_ndim\n",
    "\n",
    "        # Decompress latent\n",
    "        self.layers.append(\n",
    "            torch.nn.Linear(\n",
    "                in_features=latent_ndim,\n",
    "                out_features=linear_ndim,\n",
    "            )\n",
    "        )\n",
    "        self.layers.append(torch.nn.ReLU())\n",
    "\n",
    "        # Reshape for conv upsampling\n",
    "        self.layers.append(\n",
    "            torch.nn.Unflatten(1, (channels[0], smallest_conv_ndim))\n",
    "        )\n",
    "\n",
    "        channels = channels + [1]\n",
    "        for ii, (old_n_channels, new_n_channels) in enumerate(\n",
    "            zip(channels[:-1], channels[1:])\n",
    "        ):\n",
    "            self.layers.append(\n",
    "                torch.nn.ConvTranspose1d(\n",
    "                    in_channels=old_n_channels,\n",
    "                    out_channels=new_n_channels,\n",
    "                    kernel_size=3,\n",
    "                    padding=1,\n",
    "                    padding_mode=\"zeros\",\n",
    "                    stride=2,\n",
    "                    output_padding=1,\n",
    "                )\n",
    "            )\n",
    "            if ii < len(channels) - 2:\n",
    "                self.layers.append(\n",
    "                    torch.nn.Conv1d(\n",
    "                        in_channels=new_n_channels,\n",
    "                        out_channels=new_n_channels,\n",
    "                        kernel_size=3,\n",
    "                        padding=1,\n",
    "                        padding_mode=\"replicate\",\n",
    "                        stride=1,\n",
    "                    )\n",
    "                )\n",
    "            self.layers.append(torch.nn.ReLU())\n",
    "\n",
    "        # Remove last ReLU\n",
    "        self.layers.pop(-1)\n",
    "\n",
    "        # Remove channel dim (default is Flatten(..., start_dim=1))\n",
    "        self.layers.append(torch.nn.Flatten())\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.layers(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1842225d",
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    dec = MyDecoder()\n",
    "\n",
    "    X_prime = dec(X_latent_h)\n",
    "    assert (\n",
    "        X_prime.squeeze(1).shape == X_test.shape\n",
    "    ), f\"{X_prime.squeeze(1).shape} != {X_test.shape}\"\n",
    "\n",
    "    print(f\"{X_latent_h[:1, ...].shape=}\")\n",
    "    print(model_summary(dec, input_size=X_latent_h[:1, ...].shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "878bfcdd",
   "metadata": {
    "cell_marker": "\"\"\""
   },
   "source": [
    "Now we have all the lego bricks in place to compose an autoencoder. We do\n",
    "this by combining the encoder and decoder in yet another `torch.nn.Module`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8c09923",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyAutoencoder(torch.nn.Module):\n",
    "    def __init__(\n",
    "        self, enc_channels=[8, 16, 32], latent_ndim=10, input_ndim=40\n",
    "    ):\n",
    "        super().__init__()\n",
    "\n",
    "        self.enc = MyEncoder(\n",
    "            channels=enc_channels,\n",
    "            input_ndim=input_ndim,\n",
    "            latent_ndim=latent_ndim,\n",
    "        )\n",
    "\n",
    "        # The decoder is a flipped encoder, so we use enc_channels in reversed\n",
    "        # order.\n",
    "        self.dec = MyDecoder(\n",
    "            channels=enc_channels[::-1],\n",
    "            latent_ndim=latent_ndim,\n",
    "            output_ndim=input_ndim,\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        # construct the latents\n",
    "        h = self.enc(x)\n",
    "\n",
    "        # perform reconstruction\n",
    "        x_prime = self.dec(h)\n",
    "\n",
    "        return x_prime"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6c84d3e",
   "metadata": {
    "cell_marker": "\"\"\""
   },
   "source": [
    "We can test our autoencoder to make sure it works as expected similar to what we did above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9d1e5cb",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    model = MyAutoencoder()\n",
    "    X_prime = model(X_test)\n",
    "\n",
    "    assert (\n",
    "        X_prime.squeeze(1).shape == X_test.shape\n",
    "    ), f\"{X_prime.squeeze(1).shape} != {X_test.shape}\"\n",
    "\n",
    "    print(f\"{X_test[:1, ...].shape=}\")\n",
    "    print(model_summary(model, input_size=X_test[:1, ...].shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5527dce",
   "metadata": {
    "cell_marker": "\"\"\""
   },
   "source": [
    "## Training an autoencoder\n",
    "\n",
    "Training the autoencoder requires these steps:\n",
    "\n",
    "1. create the dataset\n",
    "2. create the loaders\n",
    "3. setup the model\n",
    "4. setup the optimizer\n",
    "5. loop through epochs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4322f6b8",
   "metadata": {
    "cell_marker": "\"\"\""
   },
   "source": [
    "### Data\n",
    "\n",
    "Fist, we prepare the data. We use a torch feature `StackDataset` to combine\n",
    "noisy inputs and clean targets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "817f2334",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dataloaders(denoising=True, batch_size=64):\n",
    "    # clean data\n",
    "    dataset_train_clean = MNIST1D(mnist1d_args=clean_config, train=True)\n",
    "    dataset_test_clean = MNIST1D(mnist1d_args=clean_config, train=False)\n",
    "    assert len(dataset_train_clean) == 3600\n",
    "    assert len(dataset_test_clean) == 400\n",
    "\n",
    "    if denoising:\n",
    "        # noisy data\n",
    "        dataset_train_noisy = MNIST1D(mnist1d_args=noisy_config, train=True)\n",
    "        dataset_test_noisy = MNIST1D(mnist1d_args=noisy_config, train=False)\n",
    "        assert len(dataset_train_noisy) == 3600\n",
    "        assert len(dataset_test_noisy) == 400\n",
    "\n",
    "        dataset_train_input = dataset_train_noisy\n",
    "        dataset_train_output = dataset_train_clean\n",
    "        dataset_test_input = dataset_test_noisy\n",
    "        dataset_test_output = dataset_test_clean\n",
    "    else:\n",
    "        dataset_train_input = dataset_train_clean\n",
    "        dataset_train_output = dataset_train_clean\n",
    "        dataset_test_input = dataset_test_clean\n",
    "        dataset_test_output = dataset_test_clean\n",
    "\n",
    "    # stacked as paired sequences, like Python's zip()\n",
    "    dataset_train = torch.utils.data.StackDataset(\n",
    "        dataset_train_input, dataset_train_output\n",
    "    )\n",
    "    dataset_test = torch.utils.data.StackDataset(\n",
    "        dataset_test_input, dataset_test_output\n",
    "    )\n",
    "\n",
    "    train_dataloader = DataLoader(\n",
    "        dataset_train, batch_size=batch_size, shuffle=True\n",
    "    )\n",
    "    test_dataloader = DataLoader(\n",
    "        dataset_test, batch_size=batch_size, shuffle=False\n",
    "    )\n",
    "\n",
    "    return train_dataloader, test_dataloader"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da9c9220",
   "metadata": {},
   "source": [
    "\n",
    "Let's inspect the data produced by the `DataLoader`. We look at the first batch\n",
    "of data, which we create by letting `train_dataloader` run one iteration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e17ee34d",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "train_dataloader, test_dataloader = get_dataloaders(\n",
    "    batch_size=batch_size, denoising=True\n",
    ")\n",
    "\n",
    "train_noisy, train_clean = next(iter(train_dataloader))\n",
    "\n",
    "X_train_noisy, y_train_noisy = train_noisy\n",
    "X_train_clean, y_train_clean = train_clean\n",
    "\n",
    "print(f\"{len(train_noisy)=} {len(train_clean)=}\")\n",
    "print(f\"{X_train_noisy.shape=} {y_train_noisy.shape=}\")\n",
    "print(f\"{X_train_clean.shape=} {y_train_clean.shape=}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d35919dc",
   "metadata": {
    "cell_marker": "\"\"\""
   },
   "source": [
    "We observe:\n",
    "\n",
    "* The `DataLoader` (via the `MNIST1D` custom Dataset) has added a channel\n",
    "  dimension, such that in each batch of `batch_size=64`, `X.shape` is `[64, 1,\n",
    "  40]` rather than `[64, 40]`. That is just a convenience feature. Our model can\n",
    "  handle either.\n",
    "* The `DataLoader` also returns the labels `y_train_*` since that is part of the\n",
    "  MNIST-1D Dataset. We will discard them below, since for training an\n",
    "  autoencoder, we only need the inputs `X`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a958a92",
   "metadata": {
    "cell_marker": "\"\"\""
   },
   "source": [
    "Now lets iterate through the data and verify that we combined the correct noisy\n",
    "and clean data points using `StackDataset`. We will look at the first couple of\n",
    "batches only. For each batch, we plot noisy and clean data for a randomly\n",
    "picked data point `idx_in_batch`, which can be any number between 0 and\n",
    "`batch_size - 1`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "290a8970",
   "metadata": {},
   "outputs": [],
   "source": [
    "grid = gridspec.GridSpec(nrows=3, ncols=4)\n",
    "fig = plt.figure(figsize=(5 * grid.ncols, 5 * grid.nrows))\n",
    "\n",
    "ax = None\n",
    "for batch_idx, (gs, (train_noisy, train_clean)) in enumerate(\n",
    "    zip(grid, train_dataloader)\n",
    "):\n",
    "    X_train_noisy, y_train_noisy = train_noisy\n",
    "    X_train_clean, y_train_clean = train_clean\n",
    "    assert (y_train_noisy == y_train_clean).all()\n",
    "    if ax is None:\n",
    "        ax = fig.add_subplot(gs)\n",
    "    else:\n",
    "        ax = fig.add_subplot(gs, sharey=ax)\n",
    "    idx_in_batch = np.random.randint(0, len(y_train_noisy))\n",
    "    ax.plot(\n",
    "        X_train_noisy[idx_in_batch].squeeze(), label=\"noisy\", color=color_noisy\n",
    "    )\n",
    "    ax.plot(\n",
    "        X_train_clean[idx_in_batch].squeeze(), label=\"clean\", color=color_clean\n",
    "    )\n",
    "    title = \"\\n\".join(\n",
    "        (\n",
    "            f\"batch={batch_idx+1} {idx_in_batch=}\",\n",
    "            f\"labels: noisy={y_train_noisy[idx_in_batch]} clean={y_train_clean[idx_in_batch]}\",\n",
    "        )\n",
    "    )\n",
    "    ax.set_title(title)\n",
    "    ax.legend()\n",
    "\n",
    "fig.savefig(\"mnist1d_random_from_dataloader.svg\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3565daa",
   "metadata": {
    "cell_marker": "\"\"\""
   },
   "source": [
    "### Model setup, hyper-parameters, training\n",
    "\n",
    "Let's define a helper function that will run the training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62326f10",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_autoencoder(\n",
    "    model,\n",
    "    optimizer,\n",
    "    loss_func,\n",
    "    train_dataloader,\n",
    "    test_dataloader,\n",
    "    max_epochs,\n",
    "    log_every=5,\n",
    "    use_gpu=False,\n",
    "    logs=defaultdict(list),\n",
    "):\n",
    "    if use_gpu and torch.cuda.is_available():\n",
    "        device = torch.device(\"cuda:0\")\n",
    "    else:\n",
    "        device = torch.device(\"cpu\")\n",
    "\n",
    "    model = model.to(device)\n",
    "\n",
    "    for epoch in range(max_epochs):\n",
    "        # For calculating loss averages in one epoch\n",
    "        train_loss_epoch_sum = 0.0\n",
    "        test_loss_epoch_sum = 0.0\n",
    "\n",
    "        model.train()\n",
    "        for train_noisy, train_clean in train_dataloader:\n",
    "            # Discard labels if using StackDataset\n",
    "            if isinstance(train_noisy, Sequence):\n",
    "                X_train_noisy = train_noisy[0]\n",
    "                X_train_clean = train_clean[0]\n",
    "            else:\n",
    "                X_train_noisy = train_noisy\n",
    "                X_train_clean = train_clean\n",
    "\n",
    "            # forward pass\n",
    "            X_prime_train = model(X_train_noisy.to(device))\n",
    "\n",
    "            # compute loss\n",
    "            train_loss = loss_func(\n",
    "                X_prime_train, X_train_clean.squeeze().to(device)\n",
    "            )\n",
    "\n",
    "            # compute gradient\n",
    "            train_loss.backward()\n",
    "\n",
    "            # apply weight update rule\n",
    "            optimizer.step()\n",
    "\n",
    "            # set gradients to 0\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            train_loss_epoch_sum += train_loss.item()\n",
    "\n",
    "        model.eval()\n",
    "        for test_noisy, test_clean in test_dataloader:\n",
    "            # Discard labels if using StackDataset\n",
    "            if isinstance(test_noisy, Sequence):\n",
    "                X_test_noisy = test_noisy[0]\n",
    "                X_test_clean = test_clean[0]\n",
    "            else:\n",
    "                X_test_noisy = test_noisy\n",
    "                X_test_clean = test_clean\n",
    "\n",
    "            X_prime_test = model(X_test_noisy.to(device))\n",
    "            test_loss = loss_func(\n",
    "                X_prime_test, X_test_clean.squeeze().to(device)\n",
    "            )\n",
    "            test_loss_epoch_sum += test_loss.item()\n",
    "\n",
    "        logs[\"train_loss\"].append(train_loss_epoch_sum / len(train_dataloader))\n",
    "        logs[\"test_loss\"].append(test_loss_epoch_sum / len(test_dataloader))\n",
    "\n",
    "        if (epoch + 1) % log_every == 0 or (epoch + 1) == max_epochs:\n",
    "            print(\n",
    "                f\"{epoch+1:02.0f}/{max_epochs} :: training loss {train_loss.mean():03.5f}; test loss {test_loss.mean():03.5f}\"\n",
    "            )\n",
    "    return logs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b25bd76",
   "metadata": {
    "cell_marker": "\"\"\""
   },
   "source": [
    "Now we define the autoencoder model, the optimizer, the loss function, as well\n",
    "as hyper-parameters such as the optimizer step size (`learning_rate`).\n",
    "\n",
    "Again, we inspect the model using `model_summary()`. This time, we use an input\n",
    "tensor from `train_dataloader`, which has shape `[batch_size, 1, 40]`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fab4bd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# hyper-parameters that influence model and training\n",
    "learning_rate = 1e-3\n",
    "latent_ndim = 10\n",
    "\n",
    "# Fast train, small model\n",
    "max_epochs = 20\n",
    "enc_channels = [8, 16, 32]\n",
    "\n",
    "# Longer train, bigger model.\n",
    "##max_epochs = 50\n",
    "##enc_channels = [32, 64, 128]\n",
    "\n",
    "# Regularization parameter to prevent overfitting. This is the AdamW\n",
    "# optimizer's default value.\n",
    "weight_decay = 0.01\n",
    "\n",
    "# Defined above already. We skip this here since this is a bit slow. If you\n",
    "# want to change batch_size (yet another hyper-parameter!) do it here or in the\n",
    "# cell above where we called get_dataloaders().\n",
    "##batch_size = 64\n",
    "##train_dataloader, test_dataloader = get_dataloaders(\n",
    "##    batch_size=batch_size, denoising=True\n",
    "##)\n",
    "\n",
    "model = MyAutoencoder(enc_channels=enc_channels, latent_ndim=latent_ndim)\n",
    "optimizer = torch.optim.AdamW(\n",
    "    model.parameters(), lr=learning_rate, weight_decay=weight_decay\n",
    ")\n",
    "loss_func = torch.nn.MSELoss()\n",
    "\n",
    "# Initialize empty loss logs once.\n",
    "logs = defaultdict(list)\n",
    "\n",
    "print(\n",
    "    model_summary(model, input_size=next(iter(train_dataloader))[0][0].shape)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "941f1f01",
   "metadata": {
    "cell_marker": "\"\"\""
   },
   "source": [
    "Run training.\n",
    "\n",
    "Note that if you re-execute this cell with*out* reinstantiating `model` above,\n",
    "you will continue training with the so-far best model as start point. Also, we\n",
    "append loss histories to `logs`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70fa7ac6",
   "metadata": {},
   "outputs": [],
   "source": [
    "logs = train_autoencoder(\n",
    "    model=model,\n",
    "    optimizer=optimizer,\n",
    "    loss_func=loss_func,\n",
    "    train_dataloader=train_dataloader,\n",
    "    test_dataloader=test_dataloader,\n",
    "    max_epochs=max_epochs,\n",
    "    log_every=5,\n",
    "    logs=logs,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "376d780b",
   "metadata": {
    "cell_marker": "\"\"\""
   },
   "source": [
    "### Plot loss (train progress) and predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3928dd5",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "# Move model to CPU (only if a GPU was used, else this does nothing) and put in\n",
    "# eval mode.\n",
    "model = model.cpu()\n",
    "model.eval()\n",
    "\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax.plot(logs[\"train_loss\"], color=\"b\", label=\"train\")\n",
    "ax.plot(logs[\"test_loss\"], color=\"orange\", label=\"test\")\n",
    "ax.set_xlabel(\"epoch\")\n",
    "ax.set_ylabel(\"average MSE Loss / a.u.\")\n",
    "ax.set_yscale(\"log\")\n",
    "ax.set_title(\"Loss\")\n",
    "ax.legend()\n",
    "fig.savefig(\"mnist1d_noisy_conv_autoencoder_loss.svg\")\n",
    "\n",
    "\n",
    "with torch.no_grad():\n",
    "    grid = gridspec.GridSpec(nrows=3, ncols=4)\n",
    "    fig = plt.figure(figsize=(5 * grid.ncols, 5 * grid.nrows))\n",
    "\n",
    "    ax = None\n",
    "    for batch_idx, (gs, (test_noisy, test_clean)) in enumerate(\n",
    "        zip(grid, test_dataloader)\n",
    "    ):\n",
    "        X_test_noisy, y_test_noisy = test_noisy\n",
    "        X_test_clean, y_test_clean = test_clean\n",
    "        assert (y_test_noisy == y_test_clean).all()\n",
    "        if ax is None:\n",
    "            ax = fig.add_subplot(gs)\n",
    "        else:\n",
    "            ax = fig.add_subplot(gs, sharey=ax)\n",
    "        idx_in_batch = np.random.randint(0, len(y_test_noisy))\n",
    "        ax.plot(\n",
    "            X_test_noisy[idx_in_batch].squeeze(),\n",
    "            label=\"noisy\",\n",
    "            color=color_noisy,\n",
    "        )\n",
    "        ax.plot(\n",
    "            X_test_clean[idx_in_batch].squeeze(),\n",
    "            label=\"clean\",\n",
    "            color=color_clean,\n",
    "        )\n",
    "        ax.plot(\n",
    "            model(X_test_noisy[idx_in_batch]).squeeze(),\n",
    "            label=\"prediction\",\n",
    "            color=\"tab:red\",\n",
    "            lw=2,\n",
    "        )\n",
    "        title = \"\\n\".join(\n",
    "            (\n",
    "                f\"batch={batch_idx+1} {idx_in_batch=}\",\n",
    "                f\"labels: noisy={y_test_noisy[idx_in_batch]} clean={y_test_clean[idx_in_batch]}\",\n",
    "            )\n",
    "        )\n",
    "        ax.set_title(title)\n",
    "        ax.legend()\n",
    "\n",
    "fig.savefig(\"mnist1d_noisy_conv_autoencoder_predictions.svg\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf1577e2",
   "metadata": {
    "cell_marker": "\"\"\""
   },
   "source": [
    "## **Exercise 04.1** Vary autoencoder hyper-parameters\n",
    "\n",
    "We can see that the autoencoder smoothed the input signal when producing a\n",
    "reconstruction.\n",
    "\n",
    "However, the model predictions, i.e. the denoised reconstructions of clean\n",
    "data, are actually not very good when using, say `max_epochs=20` and\n",
    "`enc_channels=[8, 16, 32]`. We have too much smoothing in some parts of a\n",
    "signal, following the input signal too much in other parts. The same could\n",
    "probably be achieved by a much simpler method such as a moving average or a\n",
    "Gaussian blur :) Also, looking at the loss plot, it seems that the training is\n",
    "not yet converged.\n",
    "\n",
    "Try to improve this by varying the following parameters and observe their\n",
    "effect on the reconstruction. Re-execute the cells above which define the model,\n",
    "set the hyper-parameters and run the training.\n",
    "\n",
    "Training:\n",
    "\n",
    "* `max_epochs`: try training for 100 or 200 epochs, watch out for\n",
    "  **overfitting**, when test loss > train loss\n",
    "* `learning_rate`: try 10x and 1/10 of the value above\n",
    "\n",
    "Model architecture:\n",
    "\n",
    "* `enc_channels`: try more channels per convolution, such as `[32,64,128]` or\n",
    "  `[64,128,256]`\n",
    "* `latent_ndim`: the default is 10, try setting it to 2 or 20, what happens?\n",
    "\n",
    "To do that, locate the cell above were we have\n",
    "\n",
    "```py\n",
    "learning_rate = 1e-3\n",
    "max_epochs = 50\n",
    "latent_ndim = 10\n",
    "enc_channels = [8, 16, 32]\n",
    "```\n",
    "\n",
    "and change parameters as needed. The re-execute all following cells.\n",
    "\n",
    "Note on `enc_channels`: Deeper models with more conv steps such as\n",
    "`[8,16,32,64,128,256]` is not possible with our code since in the encoder we\n",
    "half the dimension with every conv step using strided convolutions: 40 - 20 -\n",
    "10 - 5 (and double them in the decoder). The dimension in each step must be (a)\n",
    "a multiple of 2 and (b) non-zero. To make the model deeper, we'd need to drop\n",
    "strided convolutions and use another way to shrink the dimension, e.g. by\n",
    "combining normal `stride=1` convolutions with max or average pooling layers."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "482b7225",
   "metadata": {
    "cell_marker": "\"\"\""
   },
   "source": [
    "## Visualize the latent space\n",
    "\n",
    "The autoencoder's main selling point is to compress data into the latent space\n",
    "vectors / codes / embeddings `h`. Now we have a closer look at them.\n",
    "\n",
    "We now plot, separate for each label, each clean `X_test_clean[i]` and the\n",
    "latent embedding `h=enc(X_test_noisy[i])` of the noisy input. Do we find a\n",
    "correspondence between input and latent representation?\n",
    "\n",
    "Note: We plot the clean data version to better visualize the data\n",
    "characteristics without noise overlay. But we calculate the latent `h` using\n",
    "the noisy inputs because that is what the autoencoder was trained with. To\n",
    "use only the trained encoder part we use `model.enc(X)`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7444d554",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    model.eval()\n",
    "    colors = colors_10\n",
    "\n",
    "    # 2x 10 figures for our 10 labels [0,1,...,9]\n",
    "    grid_data = gridspec.GridSpec(nrows=2, ncols=5)\n",
    "    grid_latent = gridspec.GridSpec(nrows=2, ncols=5)\n",
    "\n",
    "    fig_data = plt.figure(\n",
    "        figsize=(5 * grid_data.ncols, 5 * grid_data.nrows),\n",
    "        layout=\"tight\",\n",
    "    )\n",
    "    fig_latent = plt.figure(\n",
    "        figsize=(5 * grid_latent.ncols, 5 * grid_latent.nrows),\n",
    "        layout=\"tight\",\n",
    "    )\n",
    "\n",
    "    axs_data = []\n",
    "    for label, gs in enumerate(grid_data):\n",
    "        if len(axs_data) == 0:\n",
    "            axs_data.append(fig_data.add_subplot(gs))\n",
    "        else:\n",
    "            axs_data.append(fig_data.add_subplot(gs, sharey=axs_data[-1]))\n",
    "        axs_data[-1].set_title(f\"clean data, {label=}\")\n",
    "    axs_latent = []\n",
    "    for label, gs in enumerate(grid_latent):\n",
    "        if len(axs_latent) == 0:\n",
    "            axs_latent.append(fig_latent.add_subplot(gs))\n",
    "        else:\n",
    "            axs_latent.append(\n",
    "                fig_latent.add_subplot(gs, sharey=axs_latent[-1])\n",
    "            )\n",
    "        axs_latent[-1].set_title(f\"latent h, {label=}\")\n",
    "\n",
    "    X_latent_h = []\n",
    "    y_latent_h = []\n",
    "    for test_noisy, test_clean in test_dataloader:\n",
    "        X_test_noisy, y_test_noisy = test_noisy\n",
    "        X_test_clean, y_test_clean = test_clean\n",
    "        assert (y_test_noisy == y_test_clean).all()\n",
    "        for idx_in_batch in range(len(y_test_clean)):\n",
    "            y_i = y_test_clean[idx_in_batch]\n",
    "            axs_data[y_i].plot(\n",
    "                X_test_clean[idx_in_batch].squeeze(), color=colors[y_i]\n",
    "            )\n",
    "            h = model.enc(X_test_noisy[idx_in_batch]).squeeze()\n",
    "            axs_latent[y_i].plot(h, color=colors[y_i])\n",
    "            X_latent_h.append(h)\n",
    "            y_latent_h.append(y_i)\n",
    "\n",
    "    # To generate more latent data, we'll now also encode the train set and\n",
    "    # store its h vectors.\n",
    "    for train_noisy, train_clean in train_dataloader:\n",
    "        X_train_noisy, y_train_noisy = train_noisy\n",
    "        X_train_clean, y_train_clean = train_clean\n",
    "        assert (y_train_noisy == y_train_clean).all()\n",
    "        for idx_in_batch in range(len(y_train_clean)):\n",
    "            y_i = y_train_clean[idx_in_batch]\n",
    "            h = model.enc(X_train_noisy[idx_in_batch]).squeeze()\n",
    "            X_latent_h.append(h)\n",
    "            y_latent_h.append(y_i)\n",
    "\n",
    "    X_latent_h = np.array(X_latent_h)\n",
    "    y_latent_h = np.array(y_latent_h)\n",
    "\n",
    "\n",
    "fig_data.savefig(\"mnist1d_ae_clean_input.svg\")\n",
    "fig_latent.savefig(\"mnist1d_ae_latent_from_noisy.svg\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d00aded",
   "metadata": {
    "cell_marker": "\"\"\""
   },
   "source": [
    "The first two rows show the input data, the last two rows show the latent `h`.\n",
    "Each color represents one of the 10 class labels.\n",
    "\n",
    "We find that all latent `h` vectors look very similar, so it is hard to\n",
    "visually find clusters of embeddings that belong to a certain label.\n",
    "\n",
    "In the next lesson we will tackle that with better tooling. The last thing we\n",
    "do is save some data that we load in the next notebook. That way we don't have\n",
    "to re-train the autoencoder there.\n",
    "\n",
    "**Make sure you have trained a model that is able to faithfully denoise the\n",
    "input. Without a good enough model and hence latent `h`, the following lesson\n",
    "may lead to wrong conclusions.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "692bb03f",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "np.save(\"X_latent_h.npy\", X_latent_h)\n",
    "np.save(\"y_latent_h.npy\", y_latent_h)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c31683f3",
   "metadata": {
    "cell_marker": "\"\"\""
   },
   "source": [
    "## **(Bonus) Exercise 04.2** A simpler task? Train a plain autoencoder\n",
    "\n",
    "So far we dealt with a denoising task, where the model learns to map noisy\n",
    "inputs to clean targets.\n",
    "\n",
    "Now we look at a (maybe simpler) task, which is in fact the first application\n",
    "for which autoencoders were used: reconstruct clean targets from **clean**\n",
    "inputs, i.e. **representation learning**.\n",
    "\n",
    "To do that, locate the cell above which calls `get_dataloaders()`\n",
    "\n",
    "```py\n",
    "train_dataloader, test_dataloader = get_dataloaders(\n",
    "    batch_size=batch_size, denoising=True  # <<< change this to False\n",
    ")\n",
    "```\n",
    "\n",
    "and change `denoising` to `False`.\n",
    "\n",
    "No other change is necessary. Re-execute all following cells. Does this have an\n",
    "effect on the reconstructions?"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "formats": "ipynb,py:percent"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
