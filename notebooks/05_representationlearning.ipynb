{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "adaa05f0",
   "metadata": {
    "cell_marker": "\"\"\"",
    "lines_to_next_cell": 2
   },
   "source": [
    "# Representation Learning\n",
    "\n",
    "Effective Machine Learning is often about finding a good and flexible model\n",
    "that can represent high-dimensional data well. The autoencoder can be such an\n",
    "architecture.\n",
    "\n",
    "Here we first investigate the autoencoder's latent space. Then we train\n",
    "a classification CNN, which has a completely different task. Instead of\n",
    "learning to compress (and denoise) the data, it must classify the inputs by\n",
    "label. We will look at its latent representations of the data. Does\n",
    "it learn to pay attention to the same data characteristics to solve its task?\n",
    "\n",
    "**This notebook requires the files `X_latent_h.npy` and `y_latent_h.py` written\n",
    "by the autoencoder notebook. If those are not resent, please (re-)run this\n",
    "first.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60251111",
   "metadata": {},
   "outputs": [],
   "source": [
    "# First we need to repeat some code from the previous notebook. We could of\n",
    "# course put everything into modules and import it, which would be the correct\n",
    "# way to do it in production, but here we don't, for didactic purposes.\n",
    "\n",
    "from collections import defaultdict\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.manifold import TSNE, Isomap\n",
    "from umap import UMAP\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from mnist1d.data import get_dataset_args, make_dataset\n",
    "\n",
    "from utils import model_summary, MNIST1D, get_label_colors\n",
    "\n",
    "np.random.seed(13)\n",
    "torch.random.manual_seed(12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d17b94c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# disable noise for a clear reference\n",
    "clean_config = get_dataset_args()\n",
    "clean_config.iid_noise_scale = 0\n",
    "clean_config.corr_noise_scale = 0\n",
    "clean_config.seed = 40\n",
    "clean_mnist1d = make_dataset(clean_config)\n",
    "X_clean, y_clean = clean_mnist1d[\"x\"], clean_mnist1d[\"y\"]\n",
    "\n",
    "# use iid noise only for the time being\n",
    "noisy_config = get_dataset_args()\n",
    "noisy_config.iid_noise_scale = 0.05\n",
    "noisy_config.corr_noise_scale = 0\n",
    "noisy_config.seed = 40\n",
    "noisy_mnist1d = make_dataset(noisy_config)\n",
    "X_noisy, y_noisy = noisy_mnist1d[\"x\"], noisy_mnist1d[\"y\"]\n",
    "\n",
    "# We use the same random seed for clean_config and noisy_config, so this must\n",
    "# be the same.\n",
    "assert (y_clean == y_noisy).all()\n",
    "\n",
    "# Convert numpy -> torch for usage in next cells. For training, we will build a\n",
    "# DataLoader later.\n",
    "X_noisy = torch.from_numpy(X_noisy).float()\n",
    "X_test = X_noisy[:8, ...]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36f81c45",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function is much simpler now, since we train on clean inputs and\n",
    "# targets.\n",
    "#\n",
    "def get_dataloaders(batch_size=64):\n",
    "    dataset_train_clean = MNIST1D(mnist1d_args=clean_config, train=True)\n",
    "    dataset_test_clean = MNIST1D(mnist1d_args=clean_config, train=False)\n",
    "    assert len(dataset_train_clean) == 3600\n",
    "    assert len(dataset_test_clean) == 400\n",
    "\n",
    "    train_dataloader = DataLoader(\n",
    "        dataset_train_clean, batch_size=batch_size, shuffle=True\n",
    "    )\n",
    "    test_dataloader = DataLoader(\n",
    "        dataset_test_clean, batch_size=batch_size, shuffle=False\n",
    "    )\n",
    "\n",
    "    return train_dataloader, test_dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73aae5bd",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "# Load autoencoder latent h produced by the autoencoder notebook.\n",
    "X_latent_h = np.load(\"X_latent_h.npy\")\n",
    "y_latent_h = np.load(\"y_latent_h.npy\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51c2067a",
   "metadata": {
    "cell_marker": "\"\"\""
   },
   "source": [
    "## Projection of the autoencoder latent `h` in 2D\n",
    "\n",
    "In the autoencoder lesson, we plotted the latent `h` and found it hard to find\n",
    "some structure by visual inspection.\n",
    "\n",
    "Let's now project the latent representations `h` of dimension 10 into a 2D space\n",
    "and see if we can find some structure there. For this we use [t-distributed\n",
    "Stochastic Neighbor Embedding\n",
    "(t-SNE)](https://scikit-learn.org/stable/modules/manifold.html#t-distributed-stochastic-neighbor-embedding-t-sne),\n",
    "[Uniform Manifold Approximation and Projection for Dimension Reduction\n",
    "(UMAP)](https://umap-learn.readthedocs.io)\n",
    "as well as Isomap as one additional method of the many that `scikit-learn`\n",
    "offers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c38f8134",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We'll cache things in here that we'd like to reuse instead of recomputing\n",
    "# them.\n",
    "vis_cache = defaultdict(dict)\n",
    "default_emb_name = \"umap\"\n",
    "\n",
    "emb_methods = dict(\n",
    "    tsne=lambda: TSNE(n_components=2, random_state=23),\n",
    "    umap=lambda: UMAP(n_components=2, random_state=23),\n",
    "    isomap=lambda: Isomap(n_components=2),\n",
    ")\n",
    "\n",
    "ncols = 1\n",
    "nrows = len(emb_methods)\n",
    "fig, axs = plt.subplots(\n",
    "    nrows=nrows, ncols=ncols, figsize=(5 * ncols, 5 * nrows)\n",
    ")\n",
    "label_colors = get_label_colors(y_latent_h)\n",
    "X_scaled = StandardScaler().fit_transform(X_latent_h)\n",
    "for (emb_name, emb), ax in zip(emb_methods.items(), np.atleast_1d(axs)):\n",
    "    print(f\"processing: {emb_name}\")\n",
    "    X_emb2d = emb().fit_transform(X_scaled)\n",
    "    ax.scatter(X_emb2d[:, 0], X_emb2d[:, 1], c=label_colors)\n",
    "    ax.set_title(f\"MNIST-1D latent h: {emb_name}\")\n",
    "    vis_cache[\"ae_latent_h\"][emb_name] = dict(X_emb2d=X_emb2d, y=y_latent_h)\n",
    "\n",
    "\n",
    "fig.savefig(\"mnist1d_ae_latent_embeddings_2d.svg\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9bbc387",
   "metadata": {
    "cell_marker": "\"\"\""
   },
   "source": [
    "If your autoencoder model is big enough and training is converged, you should\n",
    "see now that overall, there is no clear clustering into groups **by label**\n",
    "(the different colors) for all classes. Instead, we find some classes which are\n",
    "represented by a number of smaller \"sub-clusters\" which share the same label\n",
    "(esp. in the t-SNE and UMAP plots). Other classes don't show sub-clusters, but are\n",
    "instead scattered all over the place.\n",
    "\n",
    "In summary, there is definitely structure in the latent `h` representations\n",
    "of the data, just not one that can be easily mapped to one class label per cluster.\n",
    "So why is that? We will investigate this now in more detail.\n",
    "\n",
    "Note: Dimensionality reduction is a tricky business which by construction is a\n",
    "process where information is lost, while trying to retain the most prominent\n",
    "parts. Also, each method has hyper-parameters that need to be explored before\n",
    "over-interpreting any method's results. Still, if the model had learned to\n",
    "produce very distinct embeddings `h` per class label, we would also expect to\n",
    "see this even in a 2D space.\n",
    "\n",
    "To gain more insights, we now compute additional 2D embeddings: We\n",
    "project the MNIST-1D *inputs* of dimension 40 into a 2D space."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "950a7b25",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "cases = [\n",
    "    dict(\n",
    "        dset_name=\"MNIST-1D AE latent h, class labels\",\n",
    "        X=vis_cache[\"ae_latent_h\"][default_emb_name][\"X_emb2d\"],\n",
    "        y=vis_cache[\"ae_latent_h\"][default_emb_name][\"y\"],\n",
    "        compute=False,\n",
    "    ),\n",
    "    dict(\n",
    "        dset_name=\"MNIST-1D input (clean), class labels\",\n",
    "        X=X_clean,\n",
    "        y=y_clean,\n",
    "        compute=True,\n",
    "    ),\n",
    "    dict(\n",
    "        dset_name=\"MNIST-1D input (noisy), class labels\",\n",
    "        X=X_noisy,\n",
    "        y=y_noisy,\n",
    "        compute=True,\n",
    "    ),\n",
    "]\n",
    "\n",
    "ncols = len(cases)\n",
    "nrows = 1\n",
    "fig, axs = plt.subplots(\n",
    "    nrows=nrows, ncols=ncols, figsize=(6 * ncols, 5 * nrows)\n",
    ")\n",
    "\n",
    "for dct, ax in zip(cases, np.atleast_1d(axs)):\n",
    "    dset_name = dct[\"dset_name\"]\n",
    "    X = dct[\"X\"]\n",
    "    y = dct[\"y\"]\n",
    "    compute = dct[\"compute\"]\n",
    "    print(f\"processing: {dset_name}\")\n",
    "    if compute:\n",
    "        X_emb2d = emb_methods[default_emb_name]().fit_transform(\n",
    "            StandardScaler().fit_transform(X)\n",
    "        )\n",
    "    else:\n",
    "        X_emb2d = X\n",
    "    ax.scatter(X_emb2d[:, 0], X_emb2d[:, 1], c=get_label_colors(y))\n",
    "    n_unique_labels = len(np.unique(y))\n",
    "    ax.set_title(f\"{dset_name} \\n#labels = {n_unique_labels}\")\n",
    "\n",
    "fig.savefig(\"mnist1d_embeddings_2d_compare.svg\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6042e96",
   "metadata": {
    "cell_marker": "\"\"\"",
    "lines_to_next_cell": 2
   },
   "source": [
    "On the left we have the same 2D plot as before, a projection of the\n",
    "latent `h` into 2D space. The middle and right plots show the 2D projections of the\n",
    "40-dimensional inputs. We can make the following observations:\n",
    "\n",
    "* The input embeddings (middle and right) look very similar, so the noise we\n",
    "  added to the clean data is such that more than enough of the clean data\n",
    "  characteristics are retained, which makes learning a denoising model\n",
    "  possible in the first place.\n",
    "* The embedding of the latent `h` and that of the inputs are similar in terms of which\n",
    "  classes cluster (or not). Note that we project with t-SNE/UMAP/... 10\n",
    "  dimensional and 40 dimensional data and hence the produced 2D *shapes* are\n",
    "  not expected to be the same, as those have no meaning in those methods (see\n",
    "  [this](https://scikit-learn.org/stable/modules/manifold.html#optimizing-t-sne))\n",
    "  for more. Only the spatial distribution of the class colors is what matters.\n",
    "* Recall that the inputs and the\n",
    "  latent `h` look *very* different, yet their 2D representations are remarkably\n",
    "  similar. This shows that the latent codes `h` indeed en**code** the\n",
    "  characteristics of the data, even though their numbers (e.g. plotted in 1D)\n",
    "  appear meaningless to us. Be reminded that, just as with a standard\n",
    "  compression method (like xz, zip, lz4, ...) the compressed data looks nothing\n",
    "  like the input. You need the compressed version *plus* the compression\n",
    "  (encoder) and decompression (decoder) software. In our case, the autoencoder\n",
    "  with its learned weights is the \"software\", applicable to this dataset.\n",
    "* The left plot looks less fragmented (less sub-clusters) than even the\n",
    "  embedding of the clean data (middle). This suggests that the latent `h` carry\n",
    "  only essential information regarding the data characteristics, i.e. the\n",
    "  autoencoder managed to remove data features that are not important.\n",
    "\n",
    "But the question remains: Why don't we see one single cluster per class label?\n",
    "Two hypotheses come to mind:\n",
    "\n",
    "* The autoencoder was *not* trained to classify inputs by label, but to\n",
    "  reconstruct and denoise them. Hence the model may learn to produce latent codes\n",
    "  that help in doing that, and as a result may focus on other structural elements\n",
    "  of the data than those which a classification model would use to discriminate\n",
    "  between classes.\n",
    "\n",
    "* Given the similarity of the input and latent `h`'s 2D embeddings, maybe the\n",
    "  dataset itself is hard, in the sense that some classes can be separated by\n",
    "  input data features (the ones that show up in sub-clusters), while other\n",
    "  inputs with different class labels have in fact very similar data\n",
    "  characteristics."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "809458ec",
   "metadata": {
    "cell_marker": "\"\"\""
   },
   "source": [
    "## Classifying MNIST-1D\n",
    "\n",
    "Similar to [MNIST](https://yann.lecun.com/exdb/mnist/), MNIST-1D can be used\n",
    "for the task of classification where, given an input sequence, we\n",
    "want to predict the class label `[0,1,...,9]` that the 1D sequence belongs to.\n",
    "\n",
    "We now build a CNN classification model, the architecture of which is similar\n",
    "to our encoder from before. The main difference is that after the convolutional\n",
    "layers which do \"feature learning\" (learn what to pay attention to in the\n",
    "input), we have a small MLP that solves the classification task. We will use\n",
    "its hidden layer's activations as latent representations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a09776aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyCNN(torch.nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        channels=[8, 16, 32],\n",
    "        input_ndim=40,\n",
    "        output_ndim=10,\n",
    "        mlp_hidden_ndim=128,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.layers = torch.nn.Sequential()\n",
    "        self.final_layers = torch.nn.Sequential()\n",
    "\n",
    "        channels = [1] + channels\n",
    "        for ii, (old_n_channels, new_n_channels) in enumerate(\n",
    "            zip(channels[:-1], channels[1:])\n",
    "        ):\n",
    "            self.layers.append(\n",
    "                torch.nn.Conv1d(\n",
    "                    in_channels=old_n_channels,\n",
    "                    out_channels=new_n_channels,\n",
    "                    kernel_size=3,\n",
    "                    padding=1,\n",
    "                    padding_mode=\"replicate\",\n",
    "                    stride=2,\n",
    "                )\n",
    "            )\n",
    "            if ii < len(channels) - 1:\n",
    "                self.layers.append(\n",
    "                    torch.nn.Conv1d(\n",
    "                        in_channels=new_n_channels,\n",
    "                        out_channels=new_n_channels,\n",
    "                        kernel_size=3,\n",
    "                        padding=1,\n",
    "                        padding_mode=\"replicate\",\n",
    "                        stride=1,\n",
    "                    )\n",
    "                )\n",
    "            self.layers.append(torch.nn.ReLU())\n",
    "\n",
    "        # This layer will be used as the latent data representation of the CNN.\n",
    "        self.layers.append(torch.nn.Flatten())\n",
    "\n",
    "        dummy_X = torch.empty(1, 1, input_ndim, device=\"meta\")\n",
    "        dummy_out = self.layers(dummy_X)\n",
    "        in_features = dummy_out.shape[-1]\n",
    "\n",
    "        self.final_layers.append(\n",
    "            torch.nn.Linear(\n",
    "                in_features=in_features,\n",
    "                out_features=mlp_hidden_ndim,\n",
    "            )\n",
    "        )\n",
    "\n",
    "        self.final_layers.append(torch.nn.ReLU())\n",
    "\n",
    "        self.final_layers.append(\n",
    "            torch.nn.Linear(\n",
    "                in_features=mlp_hidden_ndim,\n",
    "                out_features=output_ndim,\n",
    "            )\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Convolutions in torch require an explicit channel dimension to be\n",
    "        # present in the data, in other words:\n",
    "        #   inputs of size (batch_size, 40) do not work,\n",
    "        #   inputs of size (batch_size, 1, 40) do work\n",
    "        if len(x.shape) == 2:\n",
    "            latent_cnn = self.layers(torch.unsqueeze(x, dim=1))\n",
    "        else:\n",
    "            latent_cnn = self.layers(x)\n",
    "\n",
    "        # In contrast to a standard forward() method, we return a tuple with\n",
    "        # the normal output and the latent representation. We account for that\n",
    "        # in the train function and in other places where we call model(X).\n",
    "        return self.final_layers(latent_cnn), latent_cnn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4494e42d",
   "metadata": {},
   "source": [
    "Next we define a function that runs the training. This function is almost the\n",
    "same as the one used for the autoencoder. The differences are:\n",
    "\n",
    "* Instead of having noisy data `X_noisy` as input and `X_clean` as target\n",
    "  (autoencoder), we now have `X_clean` as input and `y_clean` (class labels) as\n",
    "  target (classification).\n",
    "* We also record the classification accuracy in the `logs` dict."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8262d50",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score as accuracy\n",
    "\n",
    "\n",
    "def train_classifier(\n",
    "    model,\n",
    "    optimizer,\n",
    "    loss_func,\n",
    "    train_dataloader,\n",
    "    test_dataloader,\n",
    "    max_epochs,\n",
    "    log_every=5,\n",
    "    use_gpu=False,\n",
    "    logs=defaultdict(list),\n",
    "):\n",
    "    if use_gpu and torch.cuda.is_available():\n",
    "        device = torch.device(\"cuda:0\")\n",
    "    else:\n",
    "        device = torch.device(\"cpu\")\n",
    "\n",
    "    model = model.to(device)\n",
    "\n",
    "    for epoch in range(max_epochs):\n",
    "        train_loss_epoch_sum = 0.0\n",
    "        test_loss_epoch_sum = 0.0\n",
    "        train_acc_epoch_sum = 0.0\n",
    "        test_acc_epoch_sum = 0.0\n",
    "\n",
    "        model.train()\n",
    "        for X_train, y_train in train_dataloader:\n",
    "            # forward pass, discard latent_cnn here\n",
    "            y_pred_train_logits, _ = model(X_train.to(device))\n",
    "\n",
    "            train_loss = loss_func(y_pred_train_logits, y_train.to(device))\n",
    "            train_loss.backward()\n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            train_loss_epoch_sum += train_loss.item()\n",
    "            train_acc_epoch_sum += accuracy(\n",
    "                y_train, y_pred_train_logits.argmax(-1).cpu().numpy()\n",
    "            )\n",
    "\n",
    "        model.eval()\n",
    "        for X_test, y_test in test_dataloader:\n",
    "            y_pred_test_logits, _ = model(X_test.to(device))\n",
    "            test_loss = loss_func(y_pred_test_logits, y_test.to(device))\n",
    "            test_loss_epoch_sum += test_loss.item()\n",
    "            test_acc_epoch_sum += accuracy(\n",
    "                y_test, y_pred_test_logits.argmax(-1).cpu().numpy()\n",
    "            )\n",
    "\n",
    "        logs[\"train_loss\"].append(train_loss_epoch_sum / len(train_dataloader))\n",
    "        logs[\"test_loss\"].append(test_loss_epoch_sum / len(test_dataloader))\n",
    "        logs[\"train_acc\"].append(train_acc_epoch_sum / len(train_dataloader))\n",
    "        logs[\"test_acc\"].append(test_acc_epoch_sum / len(test_dataloader))\n",
    "\n",
    "        if (epoch + 1) % log_every == 0 or (epoch + 1) == max_epochs:\n",
    "            print(\n",
    "                f\"{epoch+1:02.0f}/{max_epochs} :: training loss {train_loss.mean():03.5f}; test loss {test_loss.mean():03.5f}\"\n",
    "            )\n",
    "    return logs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8499ac9f",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "train_dataloader, test_dataloader = get_dataloaders(batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8eb1d8b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# hyper-parameters that influence model and training\n",
    "learning_rate = 5e-4\n",
    "\n",
    "max_epochs = 50\n",
    "channels = [32, 64, 128]\n",
    "\n",
    "# Regularization parameter to prevent overfitting.\n",
    "weight_decay = 0.1\n",
    "\n",
    "# Defined above already. We skip this here since this is a bit slow. If you\n",
    "# want to change batch_size (yet another hyper-parameter!) do it here or in the\n",
    "# cell above where we called get_dataloaders().\n",
    "##batch_size = 64\n",
    "##train_dataloader, test_dataloader = get_dataloaders(\n",
    "##    batch_size=batch_size\n",
    "##)\n",
    "\n",
    "model = MyCNN(channels=channels)\n",
    "optimizer = torch.optim.AdamW(\n",
    "    model.parameters(), lr=learning_rate, weight_decay=weight_decay\n",
    ")\n",
    "loss_func = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "# Initialize empty loss logs once.\n",
    "logs = defaultdict(list)\n",
    "\n",
    "print(\n",
    "    model_summary(model, input_size=next(iter(train_dataloader))[0][0].shape)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aee3638c",
   "metadata": {
    "cell_marker": "\"\"\""
   },
   "source": [
    "Run training.\n",
    "\n",
    "Note that if you re-execute this cell with*out* reinstantiating `model` above,\n",
    "you will continue training with the so-far best model as start point. Also, we\n",
    "append loss histories to `logs`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "842f11cd",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "logs = train_classifier(\n",
    "    model=model,\n",
    "    optimizer=optimizer,\n",
    "    loss_func=loss_func,\n",
    "    train_dataloader=train_dataloader,\n",
    "    test_dataloader=test_dataloader,\n",
    "    max_epochs=max_epochs,\n",
    "    log_every=5,\n",
    "    logs=logs,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82382082",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 2, figsize=(10, 4))\n",
    "\n",
    "ax[0].plot(logs[\"train_loss\"], color=\"b\", label=\"train\")\n",
    "ax[0].plot(logs[\"test_loss\"], color=\"orange\", label=\"test\")\n",
    "ax[0].set_xlabel(\"epoch\")\n",
    "ax[0].set_ylabel(\"average MSE Loss / a.u.\")\n",
    "ax[0].set_yscale(\"log\")\n",
    "ax[0].set_title(\"Loss\")\n",
    "ax[0].legend()\n",
    "\n",
    "ax[1].plot(logs[\"train_acc\"], color=\"b\", label=\"train\")\n",
    "ax[1].plot(logs[\"test_acc\"], color=\"orange\", label=\"test\")\n",
    "ax[1].set_xlabel(\"epoch\")\n",
    "ax[1].set_ylabel(\"average Accuracy / a.u.\")\n",
    "ax[1].set_title(\"Accuracy\")\n",
    "ax[1].legend()\n",
    "\n",
    "fig.savefig(\"mnist1d_cnn_loss_acc.svg\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "faedd884",
   "metadata": {
    "cell_marker": "\"\"\""
   },
   "source": [
    "Let's create a 2D projection of the CNN's latent representation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f51eab41",
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    X_latent_cnn = model(torch.from_numpy(X_clean).float())[1]\n",
    "y_latent_cnn = y_clean\n",
    "\n",
    "cases = [\n",
    "    dict(\n",
    "        dset_name=\"MNIST-1D AE latent h, class labels\",\n",
    "        X=vis_cache[\"ae_latent_h\"][default_emb_name][\"X_emb2d\"],\n",
    "        y=vis_cache[\"ae_latent_h\"][default_emb_name][\"y\"],\n",
    "        compute=False,\n",
    "    ),\n",
    "    dict(\n",
    "        dset_name=\"MNIST-1D CNN latent, class labels\",\n",
    "        X=X_latent_cnn,\n",
    "        y=y_latent_cnn,\n",
    "        compute=True,\n",
    "    ),\n",
    "]\n",
    "\n",
    "ncols = len(cases)\n",
    "nrows = 1\n",
    "fig, axs = plt.subplots(\n",
    "    nrows=nrows, ncols=ncols, figsize=(6 * ncols, 5 * nrows)\n",
    ")\n",
    "\n",
    "for dct, ax in zip(cases, np.atleast_1d(axs)):\n",
    "    dset_name = dct[\"dset_name\"]\n",
    "    X = dct[\"X\"]\n",
    "    y = dct[\"y\"]\n",
    "    compute = dct[\"compute\"]\n",
    "    print(f\"processing: {dset_name}\")\n",
    "    if compute:\n",
    "        X_emb2d = emb_methods[default_emb_name]().fit_transform(\n",
    "            StandardScaler().fit_transform(X)\n",
    "        )\n",
    "    else:\n",
    "        X_emb2d = X\n",
    "    ax.scatter(X_emb2d[:, 0], X_emb2d[:, 1], c=get_label_colors(y))\n",
    "    n_unique_labels = len(np.unique(y))\n",
    "    ax.set_title(f\"{dset_name} \\n#labels = {n_unique_labels}\")\n",
    "\n",
    "fig.savefig(\"mnist1d_cnn_latent_embeddings_2d.svg\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3922f5a1",
   "metadata": {
    "cell_marker": "\"\"\""
   },
   "source": [
    "OK, well that's interesting! Now, which of the two hypotheses from above do you\n",
    "think is correct? Let's discuss!"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "formats": "ipynb,py:percent"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
