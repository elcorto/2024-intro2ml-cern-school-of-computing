{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60251111",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "from utils import count_params\n",
    "\n",
    "np.random.seed(13)\n",
    "torch.random.manual_seed(12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d17b94c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from mnist1d.data import get_dataset_args, make_dataset\n",
    "\n",
    "# disable noise for a clear reference\n",
    "clean_config = get_dataset_args()\n",
    "clean_config.iid_noise_scale = 0\n",
    "clean_config.corr_noise_scale = 0\n",
    "clean_config.seed = 40\n",
    "clean = make_dataset(clean_config)\n",
    "cleanX, cleany = clean[\"x\"], clean[\"y\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51c2067a",
   "metadata": {
    "cell_marker": "\"\"\""
   },
   "source": [
    "Now, let's plot the data which we would like to use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c38f8134",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "f, ax = plt.subplots(2, 5, figsize=(14, 5), sharex=True, sharey=True)\n",
    "\n",
    "for sample in range(10):\n",
    "    col = sample % 5\n",
    "    row = sample // 5\n",
    "    ax[row, col].plot(cleanX[sample, ...], label=\"clean\", color=\"green\")\n",
    "    label = cleany[sample]\n",
    "    ax[row, col].set_title(f\"label {label}\")\n",
    "    if row == 1:\n",
    "        ax[row, col].set_xlabel(f\"samples / a.u.\")\n",
    "    if col == 0:\n",
    "        ax[row, col].set_ylabel(f\"intensity / a.u.\")\n",
    "    if col == 4 and row == 0:\n",
    "        ax[row, col].legend()\n",
    "\n",
    "f.suptitle(\"MNIST1D examples\")\n",
    "f.savefig(\"mnist1d_cleanonly_first10.svg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "950a7b25",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyEncoder(torch.nn.Module):\n",
    "    def __init__(self, nlayers: int = 3, nchannels=16):\n",
    "        super().__init__()\n",
    "        self.layers = torch.nn.Sequential()\n",
    "\n",
    "        for i in range(nlayers - 1):\n",
    "            inchannels = 1 if i == 0 else nchannels\n",
    "            # convolve and shrink input width by 2x\n",
    "            self.layers.append(\n",
    "                torch.nn.Conv1d(\n",
    "                    in_channels=inchannels,\n",
    "                    out_channels=nchannels,\n",
    "                    kernel_size=5,\n",
    "                    padding=2,\n",
    "                    stride=2,\n",
    "                )\n",
    "            )\n",
    "            self.layers.append(torch.nn.ReLU())\n",
    "\n",
    "        # convolve and keep input width\n",
    "        self.layers.append(\n",
    "            torch.nn.Conv1d(\n",
    "                in_channels=nchannels, out_channels=1, kernel_size=3, padding=1\n",
    "            )\n",
    "        )\n",
    "\n",
    "        # flatten and add a linear tail\n",
    "        self.layers.append(torch.nn.Flatten())\n",
    "\n",
    "    def forward(self, x):\n",
    "        # convolutions in torch require an explicit channel dimension to be\n",
    "        # present in the data in other words:\n",
    "        # inputs of size (nbatch, 40) do not work,\n",
    "        # inputs of size (nbatch, 1, 40) do work\n",
    "        if len(x.shape) == 2:\n",
    "            x = torch.unsqueeze(x, dim=1)\n",
    "        return self.layers(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a09776aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyDecoder(torch.nn.Module):\n",
    "    def __init__(self, nlayers: int = 3, nchannels=16):\n",
    "        super().__init__()\n",
    "        self.layers = torch.nn.Sequential()\n",
    "\n",
    "        for i in range(nlayers - 1):\n",
    "            inchannels = 1 if i == 0 else nchannels\n",
    "            # deconvolve/Upsample and grow input width by 2x\n",
    "            self.layers.append(\n",
    "                torch.nn.ConvTranspose1d(\n",
    "                    in_channels=inchannels,\n",
    "                    out_channels=nchannels,\n",
    "                    kernel_size=5,\n",
    "                    padding=2,\n",
    "                    stride=2,\n",
    "                    output_padding=1,\n",
    "                )\n",
    "            )\n",
    "            self.layers.append(torch.nn.ReLU())\n",
    "\n",
    "        # convolve and keep input width\n",
    "        self.layers.append(\n",
    "            torch.nn.Conv1d(\n",
    "                in_channels=nchannels, out_channels=1, kernel_size=3, padding=1\n",
    "            )\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        # convolutions in torch require an explicit channel dimension to be\n",
    "        # present in the data in other words:\n",
    "        # inputs of size (nbatch, 40) do not work,\n",
    "        # inputs of size (nbatch, 1, 40) do work\n",
    "        if len(x.shape) == 2:\n",
    "            x = torch.unsqueeze(x, dim=1)\n",
    "\n",
    "        return self.layers(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8262d50",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyAutoencoder(torch.nn.Module):\n",
    "    def __init__(self, nlayers: int = 3, nchannels=16):\n",
    "        super().__init__()\n",
    "\n",
    "        self.enc = MyEncoder(nlayers, nchannels)\n",
    "        self.dec = MyDecoder(nlayers, nchannels)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # construct the latents\n",
    "        h = self.enc(x)\n",
    "\n",
    "        # perform reconstruction\n",
    "        x_prime = self.dec(h)\n",
    "\n",
    "        return x_prime"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aee3638c",
   "metadata": {
    "cell_marker": "\"\"\""
   },
   "source": [
    "## Training an autoencoder\n",
    "\n",
    "Training the autoencoder works in the same line as training for regression from the last episode.\n",
    "\n",
    "1. create the dataset\n",
    "2. create the loaders\n",
    "3. setup the model\n",
    "4. setup the optimizer\n",
    "5. loop through epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "842f11cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create dataset and loaders\n",
    "from torch.utils.data import DataLoader\n",
    "from utils import MNIST1D\n",
    "\n",
    "training_data = MNIST1D(mnist1d_args=clean_config)\n",
    "test_data = MNIST1D(mnist1d_args=clean_config, train=False)\n",
    "\n",
    "nsamples = len(training_data) + len(test_data)\n",
    "assert nsamples == 4000, f\"number of samples for MNIST1D is not 4000 but {nsamples}\"\n",
    "\n",
    "train_dataloader = DataLoader(training_data, batch_size=64, shuffle=True)\n",
    "test_dataloader = DataLoader(test_data, batch_size=64, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82382082",
   "metadata": {},
   "outputs": [],
   "source": [
    "# setup the model\n",
    "autoemodel = MyAutoencoder()\n",
    "learning_rate = 1e-3\n",
    "max_epochs = 30\n",
    "log_every = 5\n",
    "\n",
    "optimizer = torch.optim.AdamW(autoemodel.parameters(), lr=learning_rate)\n",
    "criterion = torch.nn.MSELoss()  # our loss function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f51eab41",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "# write the training loop\n",
    "def train_autoencoder(\n",
    "    model, opt, crit, train_dataloader, test_dataloader, max_epochs, log_every=5\n",
    "):\n",
    "    results = {\"train_losses\": [], \"test_losses\": []}\n",
    "    ntrainsteps = len(train_dataloader)\n",
    "    nteststeps = len(test_dataloader)\n",
    "    train_loss, test_loss = torch.zeros((ntrainsteps,)), torch.zeros((nteststeps,))\n",
    "\n",
    "    for epoch in range(max_epochs):\n",
    "        # perform training for one epoch\n",
    "        for idx, (X, _) in enumerate(train_dataloader):\n",
    "            # forward pass\n",
    "            X_prime = model(X)\n",
    "\n",
    "            # compute loss\n",
    "            loss = crit(X_prime, X)\n",
    "\n",
    "            # compute gradient\n",
    "            loss.backward()\n",
    "\n",
    "            # apply weight update rule\n",
    "            opt.step()\n",
    "\n",
    "            # set gradients to 0\n",
    "            opt.zero_grad()\n",
    "\n",
    "            train_loss[idx] = loss.item()\n",
    "\n",
    "        for idx, (X_test, _) in enumerate(test_dataloader):\n",
    "            X_prime_test = model(X_test)\n",
    "            loss_ = crit(X_prime_test, X_test)\n",
    "            test_loss[idx] = loss_.item()\n",
    "\n",
    "        results[\"train_losses\"].append(train_loss.mean())\n",
    "        results[\"test_losses\"].append(test_loss.mean())\n",
    "\n",
    "        if epoch % log_every == 0 or (epoch + 1) == max_epochs:\n",
    "            print(\n",
    "                f\"{epoch+1:02.0f}/{max_epochs} :: training loss {train_loss.mean():03.4f}; test loss {test_loss.mean():03.4f}\"\n",
    "            )\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b722c662",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [],
   "source": [
    "# run the training\n",
    "print(f\"Initialized autoencoder with {count_params(autoemodel)} parameters\")\n",
    "results = train_autoencoder(\n",
    "    autoemodel,\n",
    "    optimizer,\n",
    "    criterion,\n",
    "    train_dataloader,\n",
    "    test_dataloader,\n",
    "    max_epochs,\n",
    "    log_every,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b554e059",
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualize the training progress\n",
    "f, ax = plt.subplots(1, 2, figsize=(10, 4))\n",
    "\n",
    "ax[0].plot(results[\"train_losses\"], color=\"b\", label=\"train\")\n",
    "ax[0].plot(results[\"test_losses\"], color=\"orange\", label=\"test\")\n",
    "ax[0].set_xlabel(\"epoch\")\n",
    "ax[0].set_ylabel(\"avergage MSE Loss / a.u.\")\n",
    "ax[0].set_yscale(\"log\")\n",
    "ax[0].set_title(\"Loss\")\n",
    "ax[0].legend()\n",
    "\n",
    "# choose an index into the test set of your liking\n",
    "index = 0\n",
    "# perform prediction again\n",
    "last_x, last_y = test_data[index]\n",
    "last_x_prime = autoemodel(last_x.unsqueeze(0))\n",
    "\n",
    "# prepare tensors for plotting\n",
    "last_in = last_x.detach().squeeze().numpy()\n",
    "last_out = last_x_prime.detach().squeeze().numpy()\n",
    "\n",
    "ax[1].plot(last_in, color=\"b\", label=\"test input\")\n",
    "ax[1].plot(last_out, color=\"orange\", label=\"test prediction\")\n",
    "ax[1].set_xlabel(\"samples / a.u.\")\n",
    "ax[1].set_ylabel(\"intensity / a.u.\")\n",
    "ax[1].set_title(f\"Conv-based Autoencoder, label = {last_y.detach().item()}\")\n",
    "ax[1].legend()\n",
    "\n",
    "f.savefig(\"representationlearning-autoencoder-loss.svg\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b61eb59",
   "metadata": {
    "cell_marker": "\"\"\"",
    "lines_to_next_cell": 1
   },
   "source": [
    "# Representation Learning\n",
    "\n",
    "Effective Machine Learning is often about finding a good and flexible model that can represent high-dimensional data well. The autoencoder can be such an architecture depending on its design and the input data. In practice, the community has started to use the latent representation for all kinds of applications. But you should be aware, that the created representations can be task specific.\n",
    "\n",
    "## Classifying MNIST1D\n",
    "\n",
    "Similar to [MNIST](https://yann.lecun.com/exdb/mnist/), `mnist1d` can be used for the task of classification. In other words, given an input sequence, we only want to predict the class label `[0,1,...,9]` that the image belongs to. Classification has been one of the driving forces behind progress in machine learning since [ImageNet 2012]() - for better or worse. In science, classification is used rarely."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac7f8395",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "# taken from https://github.com/greydanus/mnist1d/blob/dc46206f1e1ad7249c96e3042efca0955a6b5d35/notebooks/models.py#L36C1-L54C65\n",
    "class ConvBase(torch.nn.Module):\n",
    "    def __init__(self, output_size, channels=25, linear_in=10):\n",
    "        super(ConvBase, self).__init__()\n",
    "        self.conv1 = torch.nn.Conv1d(1, channels, 5, stride=2, padding=2)\n",
    "        self.conv2 = torch.nn.Conv1d(channels, channels, 3, stride=2, padding=1)\n",
    "        self.conv3 = torch.nn.Conv1d(channels, channels, 3, stride=1, padding=1)\n",
    "        self.linear = torch.nn.Linear(\n",
    "            linear_in * channels, output_size\n",
    "        )  # flattened channels -> 10 (assumes input has dim 50)\n",
    "\n",
    "    def forward(self, x, verbose=False):  # the print statements are for debugging\n",
    "        x = x.view(-1, 1, x.shape[-1])\n",
    "        h1 = self.conv1(x).relu()\n",
    "        h2 = self.conv2(h1).relu()\n",
    "        h3 = self.conv3(h2).relu()\n",
    "        h3 = h3.view(h3.shape[0], -1)  # flatten the conv features\n",
    "        return self.linear(h3)  # a linear classifier goes on top"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48b20186",
   "metadata": {
    "cell_marker": "r\"\"\""
   },
   "source": [
    "**Exercise 05.1**\n",
    "\n",
    "We looked at classification in exercise 02. Pick up the notebook from there, compare the code of the `MyCNN` class with `ConvBase` above. What differences do you spot?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7b776a1",
   "metadata": {
    "cell_marker": "r\"\"\"",
    "jupyter": {
     "source_hidden": true
    }
   },
   "source": [
    "**Solution 05.1**\n",
    "\n",
    "Convolution setup:\n",
    "- MyCNN: uses convolutions with kernel sizes 5,5,3\n",
    "- ConvBase: uses convolutions with kernel sizes 5,3,3\n",
    "\n",
    "Tensor Views:\n",
    "- MyCNN: uses a flatten layer\n",
    "- ConvBase: uses a reshaped view of h3, views are powerful concepts in pytorch with which you can reshape a tensor without touching its memory\n",
    "\n",
    "Outputs of the forward pass:\n",
    "- MyCNN: uses a Softmax after the linear layer\n",
    "- ConvBase: uses only a linear layer as the output\n",
    "\n",
    "Note, that for the latter aspect, each model returns quite content for the tensors. MyCNN does normalize the logits according to the Softmax, whereas ConvBase does not! It's fun to take away, that albeit Softmax imposes a probabilistic view on the model output, training can live without it sometimes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1d76ad1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score as accuracy\n",
    "\n",
    "\n",
    "def train_classifier(\n",
    "    model, opt, crit, train_dataloader, test_dataloader, max_epochs, log_every=5\n",
    "):\n",
    "    results = {\n",
    "        \"train_losses\": [],\n",
    "        \"test_losses\": [],\n",
    "        \"train_accuracy\": [],\n",
    "        \"test_accuracy\": [],\n",
    "    }\n",
    "    ntrainsteps = len(train_dataloader)\n",
    "    nteststeps = len(test_dataloader)\n",
    "    train_loss, test_loss = torch.zeros((ntrainsteps,)), torch.zeros((nteststeps,))\n",
    "    train_acc, test_acc = np.zeros((ntrainsteps,)), np.zeros((nteststeps,))\n",
    "\n",
    "    for epoch in range(max_epochs):\n",
    "        # perform training for one epoch\n",
    "        for idx, (X, y) in enumerate(train_dataloader):\n",
    "            # forward pass\n",
    "            y_hat = model(X)\n",
    "\n",
    "            # compute loss\n",
    "            loss = crit(y_hat, y)\n",
    "\n",
    "            # compute gradient\n",
    "            loss.backward()\n",
    "\n",
    "            # apply weight update rule\n",
    "            opt.step()\n",
    "\n",
    "            # set gradients to 0\n",
    "            opt.zero_grad()\n",
    "\n",
    "            train_loss[idx] = loss.item()\n",
    "            train_acc[idx] = accuracy(\n",
    "                y.detach().cpu().numpy(), y_hat.argmax(-1).cpu().numpy()\n",
    "            )\n",
    "\n",
    "        for idx, (X_test, y_test) in enumerate(test_dataloader):\n",
    "            y_hat_test = model(X_test)\n",
    "            loss_ = crit(y_hat_test, y_test)\n",
    "            test_loss[idx] = loss_.item()\n",
    "            test_acc = accuracy(\n",
    "                y_test.detach().cpu().numpy(), y_hat_test.argmax(-1).cpu().numpy()\n",
    "            )\n",
    "\n",
    "        results[\"train_losses\"].append(train_loss.mean())\n",
    "        results[\"test_losses\"].append(test_loss.mean())\n",
    "        results[\"train_accuracy\"].append(np.mean(train_acc))\n",
    "        results[\"test_accuracy\"].append(np.mean(test_acc))\n",
    "\n",
    "        if epoch % log_every == 0 or (epoch + 1) == max_epochs:\n",
    "            print(\n",
    "                f\"{epoch+1:02.0f}/{max_epochs} :: training loss {train_loss.mean():03.4f}; test loss {test_loss.mean():03.4f} \"\n",
    "                f\"training acc {np.mean(train_acc):01.4f}; test acc {np.mean(test_acc):01.4f}\"\n",
    "            )\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54de7d10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we reuse the dataloaders from above\n",
    "classmodel = ConvBase(10, channels=32)\n",
    "print(f\"Initialized ConvBase model with {count_params(classmodel)} parameters\")\n",
    "classopt = torch.optim.AdamW(classmodel.parameters(), lr=1e-3)\n",
    "classcrit = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "# train the classifier\n",
    "classifier_results = train_classifier(\n",
    "    classmodel, classopt, classcrit, train_dataloader, test_dataloader, max_epochs=30\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6428488",
   "metadata": {},
   "outputs": [],
   "source": [
    "f, ax = plt.subplots(1, 2, figsize=(10, 4))\n",
    "\n",
    "ax[0].plot(classifier_results[\"train_losses\"], color=\"b\", label=\"train\")\n",
    "ax[0].plot(classifier_results[\"test_losses\"], color=\"orange\", label=\"test\")\n",
    "ax[0].set_xlabel(\"epoch\")\n",
    "ax[0].set_ylabel(\"avergage MSE Loss / a.u.\")\n",
    "ax[0].set_yscale(\"log\")\n",
    "ax[0].set_title(\"Loss\")\n",
    "ax[0].legend()\n",
    "\n",
    "ax[1].plot(classifier_results[\"train_accuracy\"], color=\"b\", label=\"train\")\n",
    "ax[1].plot(classifier_results[\"test_accuracy\"], color=\"orange\", label=\"test\")\n",
    "ax[1].set_xlabel(\"epoch\")\n",
    "ax[1].set_ylabel(\"avergage Accuracy / a.u.\")\n",
    "ax[1].set_title(\"Accuracy\")\n",
    "ax[1].legend()\n",
    "\n",
    "f.savefig(\"representationlearning-classifier-loss.svg\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f84b1be7",
   "metadata": {
    "cell_marker": "r\"\"\""
   },
   "source": [
    "We have trained two networks:\n",
    "- an autoencoder on a reconstruction task\n",
    "- a classifier on a classification task\n",
    "\n",
    "In practice, users are often interested in using the embeddings of either. The question, we want to answer now: are the embeddings the same?\n",
    "\n",
    "At this point, we have to honor the fact, that we are dealing with a 10-dim space in either case:\n",
    "- the latent space of our autoencoder has dim=10\n",
    "- the output of our classifier (also called logits) is also dim=10\n",
    "\n",
    "To take a more closer look, we need to explore (and compare) samples from a 10-dimensional space. Quite tricky with a 2D laptop screen.\n",
    "Thus, we have to choose a good visualisation method (or any other method to check) how similar, the embeddings actually are.\n",
    "\n",
    "*Exercise 05.2*\n",
    "\n",
    "Perform the study above by fitting a 2-component PCA from `sklearn` on the embedding spaces of the test set! Fix the errors in the visible code snippet first. Then move on to visualize the first 2 components of the PCA.\n",
    "\n",
    "Bonus: If you feel like it, feel free to experiment with other techniques than PCA like [tSNE](https://scikit-learn.org/stable/modules/generated/sklearn.manifold.TSNE.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a22cbd7",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "# disable autodiff computations\n",
    "classmodel.eval()\n",
    "autoemodel.eval()\n",
    "\n",
    "alldata_loader = DataLoader(test_data, batch_size=len(test_data), shuffle=False)\n",
    "alltest_x, alltest_y = next(iter(alldata_loader))\n",
    "\n",
    "allembed_class = ...\n",
    "allembed_autoe = ...\n",
    "\n",
    "assert ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89adddce",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "classmodel.eval()\n",
    "autoemodel.eval()\n",
    "\n",
    "alldata_loader = DataLoader(test_data, batch_size=len(test_data), shuffle=False)\n",
    "alltest_x, alltest_y = next(iter(alldata_loader))\n",
    "\n",
    "allembed_class = classmodel(alltest_x)\n",
    "allembed_autoe = autoemodel.enc(alltest_x)\n",
    "\n",
    "assert allembed_autoe.shape == allembed_class.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6f81785",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "lines_to_next_cell": 0
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn import datasets\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "pca = PCA(n_components=2)\n",
    "X_class = pca.fit(allembed_class.detach().numpy()).transform(\n",
    "    allembed_class.detach().numpy()\n",
    ")\n",
    "X_autoe = pca.fit(allembed_autoe.detach().numpy()).transform(\n",
    "    allembed_autoe.detach().numpy()\n",
    ")\n",
    "\n",
    "assert X_class.shape == X_autoe.shape\n",
    "\n",
    "fig, ax = plt.subplots(2, 2, figsize=(10, 10))\n",
    "lw = 2\n",
    "\n",
    "ax[0,0].scatter(X_class[..., 0], X_class[..., 1])\n",
    "ax[0,0].set_title(\"PCA of classifier embeddings\")\n",
    "\n",
    "ax[0,1].scatter(X_autoe[..., 0], X_autoe[..., 1])\n",
    "ax[0,1].set_title(\"PCA of autoencoder embeddings\")\n",
    "\n",
    "ax[1,0].scatter(X_class[..., 0], X_class[..., 1], c = alltest_y.detach().numpy())\n",
    "ax[1,0].set_title(\"PCA of classifier embeddings\")\n",
    "\n",
    "ax[1,1].scatter(X_autoe[..., 0], X_autoe[..., 1], c = alltest_y.detach().numpy())\n",
    "ax[1,1].set_title(\"PCA of autoencoder embeddings\")\n",
    "\n",
    "fig.savefig(\"representationlearning-pca-comparison.svg\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95fe275b",
   "metadata": {
    "cell_marker": "r\"\"\""
   },
   "source": [
    "From the above we learn, that the geometries which each of the two architectures populate in the embedding space tend to be quite different. Hence, the effect of this must be taken into account in practice. Moreover, we also see how clearly different either model differentiates the dataset."
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "formats": "ipynb,py:percent"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
